.
├── account
│   ├── admin.py
│   ├── apps.py
│   ├── authentication.py
│   ├── forms.py
│   ├── __init__.py
│   ├── migrations
│   │   ├── 0001_initial.py
│   │   ├── 0002_remove_user_merge_credits_subscription_merge_credits.py
│   │   ├── __init__.py
│   │   └── __pycache__
│   ├── models.py
│   ├── __pycache__
│   ├── static
│   │   ├── assets
│   │   │   ├── examples
│   │   │   │   ├── facebook_ig
│   │   │   │   └── youtube
│   │   │   ├── how_it_works
│   │   │   └── video
│   │   │       ├── facebook_ig_examples
│   │   │       ├── how_it_works
│   │   │       ├── tiktok_examples
│   │   │       └── youtube_examples
│   │   ├── js
│   │   └── styles
│   ├── templates
│   │   └── registration
│   ├── tests.py
│   ├── urls.py
│   └── views.py
├── dependencies
│   ├── fonts
│   ├── fonts.py
│   ├── imagemagick.py
│   ├── __init__.py
│   └── voices.py
├── hooks
│   ├── admin.py
│   ├── apps.py
│   ├── forms.py
│   ├── __init__.py
│   ├── migrations
│   │   ├── 0001_initial.py
│   │   ├── 0002_hook_dimension_task_aspect_ratio.py
│   │   ├── 0003_alter_hook_hooks_content.py
│   │   ├── 0004_alter_hook_hooks_content.py
│   │   ├── __init__.py
│   │   └── __pycache__
│   ├── models.py
│   ├── __pycache__
│   ├── static
│   │   └── assets
│   ├── templates
│   ├── tests.py
│   ├── tools
│   │   ├── audio_processors.py
│   │   ├── font_utils.py
│   │   ├── processor.py
│   │   ├── __pycache__
│   │   ├── spreadsheet_extractor.py
│   │   ├── utils.py
│   │   └── video_processors.py
│   ├── urls.py
│   └── views.py
├── hooks_app
│   ├── asgi.py
│   ├── __init__.py
│   ├── __pycache__
│   ├── settings.py
│   ├── urls.py
│   └── wsgi.py
├── manage.py
├── media
│   ├── hooks_videos
│   ├── output
│   └── uploads
│       ├── 03fb71df-32b5-45db-91e6-74eb6d1acada
│       ├── 204828c9-16c3-470c-8978-2e47d10fb7fa
│       ├── 41ba410d-5848-44e3-86f8-9acc42291c14
│       └── 68fb674a-709a-4b53-b684-8cf00393be6d
├── merger
│   ├── admin.py
│   ├── apps.py
│   ├── forms.py
│   ├── __init__.py
│   ├── migrations
│   │   ├── 0001_initial.py
│   │   ├── 0002_mergetask_progress.py
│   │   ├── 0003_mergetask_total_frames.py
│   │   ├── 0004_rename_progress_mergetask_total_frames_done.py
│   │   ├── __init__.py
│   │   └── __pycache__
│   ├── models.py
│   ├── __pycache__
│   ├── static
│   ├── templates
│   │   └── merger
│   │       └── upload_files.py
│   ├── tests.py
│   ├── urls.py
│   └── views.py
├── output
└── uploads

49 directories, 55 files


--- Content of .py Files ---


--- ./account/authentication.py ---

from django.contrib.auth import get_user_model

User = get_user_model()

class EmailAuthBackend:
  """
    Authenticate using an e-mail address.
    """
  def authenticate(self, request, username=None, password=None):
    try:
      user = User.objects.get(email=username)
      if user.check_password(password):
        return user
      return None
    except (User.DoesNotExist, User.MultipleObjectsReturned):
      return None

  def get_user(self, user_id):
    try:
      return User.objects.get(pk=user_id)
    except User.DoesNotExist:
      return None

--- ./account/__init__.py ---


--- ./account/apps.py ---

from django.apps import AppConfig


class AccountConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'account'

--- ./account/admin.py ---

from django.contrib import admin
from .models import *

admin.site.register(Plan)
admin.site.register(Subscription)
admin.site.register(StripeCustomer)
admin.site.register(User)

--- ./account/migrations/__init__.py ---


--- ./account/migrations/0002_remove_user_merge_credits_subscription_merge_credits.py ---

# Generated by Django 5.1.1 on 2024-11-02 11:02

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('account', '0001_initial'),
    ]

    operations = [
        migrations.RemoveField(
            model_name='user',
            name='merge_credits',
        ),
        migrations.AddField(
            model_name='subscription',
            name='merge_credits',
            field=models.IntegerField(blank=True, null=True),
        ),
    ]

--- ./account/migrations/0001_initial.py ---

# Generated by Django 5.1.1 on 2024-11-02 08:35

import django.contrib.auth.validators
import django.db.models.deletion
import django.utils.timezone
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('auth', '0012_alter_user_first_name_max_length'),
    ]

    operations = [
        migrations.CreateModel(
            name='Plan',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('stripe_price_id', models.CharField(max_length=255, null=True)),
                ('name', models.CharField(max_length=50)),
                ('price', models.DecimalField(decimal_places=2, max_digits=5, null=True)),
                ('price_per_hook', models.DecimalField(decimal_places=2, max_digits=5, null=True)),
                ('hook_limit', models.IntegerField(default=0)),
            ],
        ),
        migrations.CreateModel(
            name='User',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('password', models.CharField(max_length=128, verbose_name='password')),
                ('last_login', models.DateTimeField(blank=True, null=True, verbose_name='last login')),
                ('is_superuser', models.BooleanField(default=False, help_text='Designates that this user has all permissions without explicitly assigning them.', verbose_name='superuser status')),
                ('username', models.CharField(error_messages={'unique': 'A user with that username already exists.'}, help_text='Required. 150 characters or fewer. Letters, digits and @/./+/-/_ only.', max_length=150, unique=True, validators=[django.contrib.auth.validators.UnicodeUsernameValidator()], verbose_name='username')),
                ('first_name', models.CharField(blank=True, max_length=150, verbose_name='first name')),
                ('last_name', models.CharField(blank=True, max_length=150, verbose_name='last name')),
                ('is_staff', models.BooleanField(default=False, help_text='Designates whether the user can log into this admin site.', verbose_name='staff status')),
                ('is_active', models.BooleanField(default=True, help_text='Designates whether this user should be treated as active. Unselect this instead of deleting accounts.', verbose_name='active')),
                ('date_joined', models.DateTimeField(default=django.utils.timezone.now, verbose_name='date joined')),
                ('email', models.EmailField(max_length=254, unique=True)),
                ('api_key', models.CharField(blank=True, max_length=255, null=True)),
                ('verification_token', models.CharField(blank=True, max_length=100, null=True)),
                ('merge_credits', models.IntegerField(blank=True, null=True)),
                ('groups', models.ManyToManyField(blank=True, help_text='The groups this user belongs to. A user will get all permissions granted to each of their groups.', related_name='user_set', related_query_name='user', to='auth.group', verbose_name='groups')),
                ('user_permissions', models.ManyToManyField(blank=True, help_text='Specific permissions for this user.', related_name='user_set', related_query_name='user', to='auth.permission', verbose_name='user permissions')),
            ],
            options={
                'verbose_name': 'user',
                'verbose_name_plural': 'users',
                'abstract': False,
            },
        ),
        migrations.CreateModel(
            name='StripeCustomer',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('stripe_customer_id', models.CharField(max_length=255)),
                ('user', models.ForeignKey(null=True, on_delete=django.db.models.deletion.CASCADE, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='Subscription',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('stripe_subscription_id', models.CharField(max_length=255, null=True)),
                ('hooks', models.IntegerField(default=0)),
                ('current_period_end', models.IntegerField(default=0)),
                ('customer', models.ForeignKey(null=True, on_delete=django.db.models.deletion.CASCADE, to='account.stripecustomer')),
                ('plan', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='account.plan')),
            ],
        ),
        migrations.AddField(
            model_name='user',
            name='subscription',
            field=models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to='account.subscription'),
        ),
    ]

--- ./account/urls.py ---

from django.urls import path
from .views import *

app_name = 'account'

urlpatterns = [
  path("", home, name="home"),
  path("stage/", stage, name="stage"),
  path("login/", login_view, name="login"),
  path("logout/", logout_user, name="logout"),
  path('register/', register, name='register'),
  path('subscription/', subscription, name='subscription'),
  path('verify/<str:token>', verify, name='verify'),
  path('subscribe/<str:price_id>', subscribe, name='subscribe'),
  path('stripe-webhook', stripe_webhook, name='stripe_webhook'),
  path('manage-subscription', manage_subscription, name='manage_subscription'),
  path('billing-portal', billing_portal, name='billing_portal'),
  path('add-credits/<str:kind>', add_credits, name='add_credits'),
  path('add-credits-success', add_credits_success, name='add_credits_success'),
  path('add-credits-cancel', add_credits_cancel, name='add_credits_cancel'),
  path(
    'upgrade-subscription/<str:price_id>',
    upgrade_subscription,
    name='upgrade_subscription'
  ),
  path(
    'downgrade-subscription',
    downgrade_subscription,
    name='downgrade_subscription'
  ),
  path('cancel-subscription', cancel_subscription, name='cancel_subscription'),
  path(
    'terms-and-conditions', terms_and_conditions, name='terms_and_conditions'
  ),
  path('privacy-policy', privacy_policy, name='privacy_policy'),
  path('refund-policy', refund_policy, name='refund_policy'),
  path('affiliate-program', affiliate_program, name='affiliate_program'),
]

--- ./account/models.py ---

from django.db import models
from django.contrib.auth.models import AbstractUser, BaseUserManager

class CustomUserManager(BaseUserManager):
  def create_user(self, email, password=None, **extra_fields):
    if not email:
      raise ValueError('The Email field must be set')
    email = self.normalize_email(email)
    user = self.model(email=email, **extra_fields)
    user.set_password(password)
    user.save(using=self._db)
    return user

  def create_superuser(self, email, password=None, **extra_fields):
    extra_fields.setdefault('is_staff', True)
    extra_fields.setdefault('is_superuser', True)
    return self.create_user(email, password, **extra_fields)

class Plan(models.Model):
  stripe_price_id = models.CharField(max_length=255, null=True)
  name = models.CharField(max_length=50)
  price = models.DecimalField(max_digits=5, decimal_places=2, null=True)
  price_per_hook = models.DecimalField(
    max_digits=5, decimal_places=2, null=True
  )
  hook_limit = models.IntegerField(default=0)

class StripeCustomer(models.Model):
  user = models.ForeignKey('User', on_delete=models.CASCADE, null=True)
  stripe_customer_id = models.CharField(max_length=255)

class Subscription(models.Model):
  plan = models.ForeignKey(Plan, on_delete=models.CASCADE)
  stripe_subscription_id = models.CharField(max_length=255, null=True)
  customer = models.ForeignKey(
    StripeCustomer, on_delete=models.CASCADE, null=True
  )
  hooks = models.IntegerField(default=0)
  merge_credits = models.IntegerField(blank=True, null=True)
  current_period_end = models.IntegerField(default=0)

class User(AbstractUser):
  email = models.EmailField(unique=True, null=False, blank=False)
  api_key = models.CharField(max_length=255, blank=True, null=True)
  verification_token = models.CharField(max_length=100, blank=True, null=True)
  subscription = models.ForeignKey(
    Subscription, on_delete=models.SET_NULL, null=True
  )

  USERNAME_FIELD = "email"
  REQUIRED_FIELDS = []

  objects = CustomUserManager()

  def save(self, *args, **kwargs):
    self.username = self.email
    super().save(*args, **kwargs)

  def can_generate_video(self):
    return self.subscription.hooks >= 1

--- ./account/tests.py ---

from django.test import TestCase

# Create your tests here.

--- ./account/forms.py ---

from django import forms
from django.contrib.auth.forms import AuthenticationForm

class CustomLoginForm(AuthenticationForm):
  username = forms.CharField(
    widget=forms.TextInput(
      attrs={
        'id': 'email',
        'type': 'email',
        'placeholder': 'Email'
      }
    )
  )
  password = forms.CharField(
    widget=forms.PasswordInput(
      attrs={
        'id': 'password',
        'type': 'password',
        'placeholder': 'Password'
      }
    )
  )

from django.core.mail import send_mail
from django.conf import settings

class ContactUsForm(forms.Form):
  full_name = forms.CharField(
    max_length=100,
    widget=forms.TextInput(
      attrs={
        "id": "full_name",
        "placeholder": "Enter Your Full Name",
        "type": "text",
      }
    ),
  )

  email = forms.EmailField(
    widget=forms.TextInput(
      attrs={
        "id": "email",
        "placeholder": "Enter your Email address",
        "type": "email",
      }
    )
  )
  message = forms.CharField(
    widget=forms.Textarea(
      attrs={
        "id": "message",
        'placeholder': "Write Us Your Question Here..."
      }
    )
  )

  def send(self):
    message = f"Full Name: {self.cleaned_data['full_name']}\n"
    message += f"Email: {self.cleaned_data['email']}\n"
    message += f"Message: {self.cleaned_data['message']}\n"

    send_mail(
      "Contact Us Form Submission",
      message,
      from_email=settings.EMAIL_HOST_USER,
      recipient_list=[settings.EMAIL_HOST_USER],
      fail_silently=False,
    )

--- ./account/views.py ---

from account.forms import ContactUsForm
from django.contrib.auth.decorators import login_required
from django.views.decorators.csrf import csrf_exempt
from django.http import HttpResponse, JsonResponse
from django.conf import settings
from django.contrib.auth import login, get_user_model, logout, authenticate
from django.contrib import messages
from django.core.mail import EmailMessage
from django.core.mail import send_mail
from django.shortcuts import render, redirect
from django.template.loader import render_to_string
from django.urls import reverse
from django.utils.html import strip_tags
from .models import Subscription, StripeCustomer, Plan
import stripe
import uuid
from datetime import datetime

def stage(request):
  return render(request, 'stage.html')

def login_view(request):
  if request.user.is_authenticated:
    return redirect('hooks:upload')

  if request.method == 'POST':
    email = request.POST['email']
    password = request.POST['password']

    user = authenticate(request, username=email, password=password)

    if user is not None:
      if user.verification_token is None:
        _login(request, user)

        try:
          return redirect(request.session.get('next'))
        except:
          return redirect('hooks:upload')
      else:
        messages.error(
          request,
          'Your Email Address Is Not Verified. Please Verify Your Email Before Logging In.'
        )
    else:
      messages.error(request, 'Invalid Username or Password. Please Try Again.')

  next = request.GET.get('next', '')
  request.session['next'] = next
  return render(
    request,
    'registration/login.html',
  )

def logout_user(request):
  if request.user.is_authenticated:
    logout(request)

  return redirect('account:home')

def home(request):
  if request.user.is_authenticated:
    return redirect('hooks:upload')

  contact_us_form = ContactUsForm(request.POST or None)

  if request.method == 'POST':
    if contact_us_form.is_valid():
      try:
        contact_us_form.send()
      except Exception as e:
        print(f'An error occurred while sending contact us message {e}')
        messages.error(request, 'Failed To Send Message')
        return redirect(reverse('account:home') + '#Contact')

      messages.success(request, 'Message Sent Successfully')
      return redirect(reverse('account:home') + '#Contact')

  return render(
    request,
    'home.html',
    {
      'contact_us_form': contact_us_form,
      'plans': Plan.objects.all(),
    },
  )

def terms_and_conditions(request):
  return render(request, 'terms_and_conditions.html')

def privacy_policy(request):
  return render(request, 'privacy_policy.html')

def refund_policy(request):
  return render(request, 'refund_policy.html')

def affiliate_program(request):
  return render(request, 'affiliate_program.html')

def register(request):
  if request.method == 'POST':
    stripe.api_key = settings.STRIPE_SEC_KEY

    checkout_session_id = request.POST.get('session_id')

    name = request.POST.get('name')
    email = request.POST.get('email')
    password1 = request.POST.get('password1')
    password2 = request.POST.get('password2')

    if len(password1) < 6:
      messages.error(request, 'At Least 6 Characters Are Required')
      return render(
        request,
        'registration/register.html',
        context={'session_id': checkout_session_id}
      )

    if password1 != password2:
      messages.error(request, 'Passwords Do Not Match.')
      return render(
        request,
        'registration/register.html',
        context={'session_id': checkout_session_id}
      )

    User = get_user_model()
    if User.objects.filter(email=email).exists():
      messages.error(request, 'This Email Is Already Registered.')
      return render(
        request,
        'registration/register.html',
        context={'session_id': checkout_session_id}
      )

    user = User.objects.create_user(email=email, password=password1)
    user.first_name = name
    user.save()

    if checkout_session_id is None:
      free_plan = Plan.objects.get(id=3)
      customer = stripe.Customer.create(
        email=user.email,
        name=user.first_name,
      )
      stripe_customer = StripeCustomer(
        user=user, stripe_customer_id=customer.id
      )
      stripe_customer.save()
      subscription = Subscription(
        plan=free_plan,
        hooks=free_plan.hook_limit,
        merge_credits=free_plan.hook_limit * 5,
        customer=stripe_customer,
        stripe_subscription_id=None
      )
      subscription.save()
      user.subscription = subscription

      verification_token = str(uuid.uuid4())
      user.verification_token = verification_token

      user.save()

      send_html_email2(
        subject='Welcome to HooksMaster.io – Verify Your Email To Continue',
        message=None,
        from_email=settings.EMAIL_HOST_USER,
        to_email=user.email,
        html_file='verification.html',
        context={
          'first_name':
            user.first_name,
          'verification_url':
            settings.DOMAIN
            + reverse('account:verify', kwargs={'token': verification_token}),
        },
      )

      return render(
        request,
        'registration/register.html',
        context={
          'price_id': 'free',
          'success': True
        }
      )
    else:
      checkout_session = stripe.checkout.Session.retrieve(checkout_session_id)
      stripe_customer_id = checkout_session.customer

      customer_id = 0
      try:
        customer = StripeCustomer.objects.get(
          stripe_customer_id=stripe_customer_id
        )

        if customer is not None:
          customer.user = user
          customer.save()

          customer_id = customer.id
      except StripeCustomer.DoesNotExist:
        new_customer = StripeCustomer(
          user=user, stripe_customer_id=stripe_customer_id
        )
        new_customer.save()

        customer_id = new_customer.id

      try:
        subscription = Subscription.objects.get(customer_id=customer_id)

        if subscription is not None:
          user.subscription = subscription
          user.save()
      except Exception as _:
        messages.error(request, "Subscription Failed. Please Try Again Later.")
        return render(
          request,
          'registration/register.html',
          context={'session_id': checkout_session_id}
        )

      send_confirmation_email(email, user.first_name)

      _login(request, user)

      return redirect("hooks:upload")
  elif request.method == 'GET':
    checkout_session_id = request.GET.get('session_id')

    return render(
      request,
      'registration/register.html',
      context={'session_id': checkout_session_id}
    )

@csrf_exempt
def stripe_webhook(request):
  stripe.api_key = settings.STRIPE_SEC_KEY

  endpoint_secret = settings.STRIPE_ENDPOINT_SECRET
  payload = request.body
  sig_header = request.META['HTTP_STRIPE_SIGNATURE']

  event = None
  try:
    event = stripe.Webhook.construct_event(payload, sig_header, endpoint_secret)
  except ValueError as _:
    return HttpResponse(status=400)
  except stripe.error.SignatureVerificationError as _:
    return HttpResponse(status=400)

  event_type = event['type']
  event_object = event['data']['object']

  if event_type == 'invoice.payment_succeeded':
    if event_object.billing_reason == 'subscription_create':
      try:
        customer_id = event_object.customer

        customer = None
        try:
          customer = StripeCustomer.objects.get(stripe_customer_id=customer_id)
        except StripeCustomer.DoesNotExist:
          customer = StripeCustomer(user=None, stripe_customer_id=customer_id)
          customer.save()

        prev_sub = None
        prev_sub_hooks = 0
        prev_sub_merges = 0
        try:
          prev_sub = Subscription.objects.get(customer_id=customer.id)

          if prev_sub is not None:
            if prev_sub.stripe_subscription_id is not None:
              stripe.Subscription.delete(prev_sub.stripe_subscription_id)

            prev_sub_hooks = prev_sub.hooks
            prev_sub_merges = prev_sub.merge_credits
        except Subscription.DoesNotExist:
          pass

        subscription_id = event_object.subscription
        price_id = event_object.lines.data[0].price.id
        plan = Plan.objects.get(stripe_price_id=price_id)
        subscription = Subscription(
          plan=plan,
          stripe_subscription_id=subscription_id,
          customer=customer,
          hooks=plan.hook_limit + prev_sub_hooks,
          merge_credits=(plan.hook_limit * 5) + prev_sub_merges
        )
        subscription.save()

        if customer.user is not None:
          customer.user.subscription = subscription
          customer.user.save()

          if prev_sub is not None:
            prev_sub.delete()
      except Exception as e:
        print(
          datetime.now().strftime("%H:%M:%S")
          + f': Error in stripe webhook: {e}'
        )
    elif event_object.billing_reason == 'subscription_cycle':
      try:
        price_id = event_object.lines.data[0].price.id
        plan = Plan.objects.get(stripe_price_id=price_id)

        subscription_id = event_object.subscription
        subscription = Subscription.objects.get(
          stripe_subscription_id=subscription_id
        )
        subscription.hooks = plan.hook_limit + subscription.hooks
        subscription.merge_credits = (
          plan.hook_limit * 5
        ) + subscription.merge_credits
        subscription.save()
      except Exception as e:
        print(
          datetime.now().strftime("%H:%M:%S")
          + f': Error in stripe webhook: {e}'
        )
  elif event_type == 'invoice.payment_failed':
    if event_object.billing_reason == 'subscription_create':
      messages.error(
        request,
        'Checkout error. Couldn\'t Complete Subsrciption Successfully. Please try again later.'
      )

      print(
        datetime.now().strftime("%H:%M:%S") +
        ': Payment Failed. Couldn\'t Complete Subsrciption Successfully. Please try again later.'
      )
    elif event_object.billing_reason == 'subscription_cycle':
      messages.error(
        request,
        'Checkout error. Couldn\'t Renew Subsrciption Successfully. Please try again later.'
      )

      print(
        datetime.now().strftime("%H:%M:%S") +
        ': Payment Failed. Couldn\'t Renew Subsrciption Successfully. Please try again later.'
      )
  elif event_type == 'customer.subscription.deleted':
    if event_object.cancel_at_period_end:
      customer_id = event_object.customer

      try:
        customer = StripeCustomer.objects.get(stripe_customer_id=customer_id)
      except StripeCustomer.DoesNotExist:
        return HttpResponse(status=404)

      sub = Subscription.objects.get(customer_id=customer.id)
      sub.hooks = 0
      sub.merge_credits = 0
      sub.save()

  return HttpResponse(status=200)

@login_required
def manage_subscription(request):
  credits_left = request.user.subscription.hooks
  total_credits = max(request.user.subscription.plan.hook_limit, credits_left)

  current_period_end = 0
  if request.user.subscription.stripe_subscription_id is not None:
    stripe.api_key = settings.STRIPE_SEC_KEY

    subscription = stripe.Subscription.retrieve(
      request.user.subscription.stripe_subscription_id
    )

    current_period_end = int(subscription['current_period_end'])
  else:
    current_period_end = request.user.subscription.current_period_end

  now = int(datetime.now().timestamp())
  days_left = int((current_period_end-now) / 60 / 60 / 24)
  days_left = max(-1, days_left)
  days_left += 1

  return render(
    request,
    'subscription.html',
    context={
      'total_credits':
        total_credits,
      'credits_left':
        credits_left,
      'cur_plan':
        request.user.subscription.plan,
      'price_per_merge':
        f"{(request.user.subscription.plan.price_per_hook / 5):.2f}",
      'plans':
        Plan.objects.all(),
      'days_left':
        days_left,
    }
  )

@login_required
def billing_portal(request):
  stripe.api_key = settings.STRIPE_SEC_KEY

  try:
    customer = StripeCustomer.objects.get(user_id=request.user.id)

    session = stripe.billing_portal.Session.create(
      customer=customer.stripe_customer_id,
      return_url=settings.DOMAIN + reverse('account:home'),
    )

    return redirect(session.url)
  except Exception as _:
    return redirect(reverse('account:home'))

def verify(request, token):
  try:
    user = get_user_model().objects.get(verification_token=token)

    if user is not None:
      user.verification_token = None
      user.save()

      _login(request, user)
      return redirect('hooks:upload')
  except:
    return redirect(reverse('account:home'))

def subscribe(request, price_id):
  if request.method == 'GET':
    try:
      stripe.api_key = settings.STRIPE_SEC_KEY

      success_path = request.GET.get('success_path')
      cancel_path = request.GET.get('cancel_path')

      customer = None
      if request.user.is_authenticated:
        customer = request.user.subscription.customer.stripe_customer_id

      checkout_session = stripe.checkout.Session.create(
        customer=customer,
        success_url=settings.DOMAIN + success_path +
        ('&' if '?' in success_path else '?')
        + 'session_id={CHECKOUT_SESSION_ID}',
        cancel_url=settings.DOMAIN + cancel_path,
        payment_method_types=['card'],
        mode='subscription',
        line_items=[{
          'price': price_id,
          'quantity': 1,
        }]
      )

      return redirect(checkout_session.url)
    except Exception as _:
      return redirect(reverse('account:home'))

@login_required
def add_credits(request, kind):
  if request.method == 'POST':
    if int(request.POST.get('credits_number')
           ) >= 1 and request.user.subscription.plan.name.lower() != 'free':
      try:
        stripe.api_key = settings.STRIPE_SEC_KEY

        unit_amount = 0
        if kind == 'hook':
          unit_amount = float(request.user.subscription.plan.price_per_hook)
        elif kind == 'merge':
          unit_amount = float(request.user.subscription.plan.price_per_hook / 5)

        checkout_session = stripe.checkout.Session.create(
          customer=request.user.subscription.customer.stripe_customer_id,
          success_url=settings.DOMAIN + reverse('account:add_credits_success')
          + f'?amount={request.POST.get("credits_number")}&kind={kind}',
          cancel_url=settings.DOMAIN + reverse('account:add_credits_cancel'),
          payment_method_types=['card'],
          line_items=[
            {
              'price_data':
                {
                  'currency': 'usd',
                  'product_data':
                    {
                      'name':
                        f'{request.POST.get("credits_number")} {kind.title()} Credits',
                    },
                  'unit_amount': int(round(unit_amount * 100)),
                },
              'quantity': int(request.POST.get('credits_number')),
            },
          ],
          mode='payment',
        )

        return redirect(checkout_session.url)
      except Exception as _:
        return redirect(reverse('account:home'))

@login_required
def add_credits_success(request):
  if request.method == 'GET':
    new_credits = int(request.GET.get('amount'))
    kind = request.GET.get('kind')

    if kind == 'hook':
      request.user.subscription.hooks += new_credits
    elif kind == 'merge':
      request.user.subscription.merge_credits += new_credits

    request.user.subscription.save()

    return redirect(reverse('account:manage_subscription') + '?recheck=true')

def add_credits_cancel(request):
  return redirect(reverse('account:manage_subscription'))

@login_required
def upgrade_subscription(request, price_id):
  return subscribe(request, price_id)

@login_required
def downgrade_subscription(request):
  try:
    if request.user.subscription.plan.id == 2:
      subscription = stripe.Subscription.retrieve(
        request.user.subscription.stripe_subscription_id
      )

      stripe.Subscription.modify(
        subscription.id,
        items=[
          {
            'id': subscription['items']['data'][0].id,
            'price': settings.STRIPE_PRICE_ID_PRO,
          }
        ],
        proration_behavior='none',
      )

      pro_plan = Plan.objects.get(id=1)
      request.user.subscription.plan = pro_plan
      request.user.subscription.save()

      return redirect(reverse('account:manage_subscription') + '?recheck=true')
  except Exception as e:
    return redirect(reverse('account:manage_subscription'))

@login_required
def cancel_subscription(request):
  stripe.api_key = settings.STRIPE_SEC_KEY

  try:
    subscription = stripe.Subscription.retrieve(
      request.user.subscription.stripe_subscription_id
    )
    stripe.Subscription.modify(
      subscription.id,
      cancel_at_period_end=True,
    )

    free_plan = Plan.objects.get(id=3)
    request.user.subscription.plan = free_plan
    request.user.subscription.stripe_subscription_id = None
    request.user.subscription.current_period_end = subscription.current_period_end
    request.user.subscription.save()

    return redirect(reverse('account:manage_subscription') + '?recheck=true')
  except Exception as _:
    return redirect(reverse('account:manage_subscription'))

@login_required
def subscription(request):
  sub = request.user.subscription

  return JsonResponse(
    {
      'plan_name': sub.plan.name.lower(),
      'stripe_subscription_id': sub.stripe_subscription_id,
      'hooks': sub.hooks,
      'merge_credits': sub.merge_credits,
      'current_period_end': sub.current_period_end
    }
  )

def send_html_email2(
  subject, message, from_email, to_email, html_file, context
):
  html_content = render_to_string(html_file, context)

  text_content = strip_tags(html_content)

  send_mail(
    subject, text_content, from_email, [to_email], html_message=html_content
  )

def send_confirmation_email(email, name):
  # HTML email content
  logi_url = settings.DOMAIN + "login"
  if name is None:
    name = "there"
  html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Welcome to HooksMaster.io</title>
</head>
<body style="font-family: Arial, sans-serif; line-height: 1.6; color: #333;">
    <div style="max-width: 600px; margin: 0 auto;">
    <h2 style="color: #2c3e50;">Hi {name},</h2>
<p>Welcome to <strong>HooksMaster.io</strong>! Your journey to creating high-converting video hooks effortlessly starts here. Your account has been successfully created, and you’re ready to optimize your ads.</p>

<h3 style="color: #2c3e50;">Next Steps:</h3>
<ul>
<li><strong>Log in:</strong> <a href="https://hooksmaster.io/login" style="color: #3498db;">Login to HooksMaster.io</a></li>
<li><strong>Get Started:</strong> Prepare your hooks and generate winning creatives.</li>
</ul>

<p>If you need support, we’re here to help. Feel free to reach out to us at <a href="mailto:support@hooksmaster.io" style="color: #3498db;">support@hooksmaster.io</a>.</p>

<p>Let’s create some high-converting hooks together!</p>

<a href="https://hooksmaster.io/login" style="display: inline-block; padding: 10px 20px; background-color: #3498db; color: white; text-decoration: none; border-radius: 5px; font-weight: bold;">Login Now</a>

<p>Best regards,</p>
<p><strong>The HooksMaster.io Team</strong></p>
</div>
</body>
</html>
    """

  email_message = EmailMessage(
    subject="Welcome to HooksMaster.io – Your Account is Ready!",
    body=html_content,
    from_email=settings.EMAIL_HOST_USER,
    to=[email],
  )
  email_message.content_subtype = "html"  # This is required to send the email as HTML
  email_message.send(fail_silently=True)

def _login(request, user):
  backend = "django.contrib.auth.backends.ModelBackend"
  user.backend = backend
  login(request, user, backend=backend)

--- ./merger/templates/merger/upload_files.py ---


--- ./merger/__init__.py ---


--- ./merger/apps.py ---

from django.apps import AppConfig


class MergerConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'merger'

--- ./merger/admin.py ---

from django.contrib import admin
from .models import MergeTask

# Register your models here.
@admin.register(MergeTask)
class TaskAdmin(admin.ModelAdmin):
    list_display = ['task_id', 'status', 'short_video_path', 'large_video_paths','video_links']
--- ./merger/migrations/__init__.py ---


--- ./merger/migrations/0004_rename_progress_mergetask_total_frames_done.py ---

from django.db import migrations

class Migration(migrations.Migration):
  dependencies = [
    ('merger', '0003_mergetask_total_frames'),
  ]

  operations = [
    migrations.RenameField(
      model_name='mergetask',
      old_name='progress',
      new_name='total_frames_done',
    ),
  ]

--- ./merger/migrations/0002_mergetask_progress.py ---

from django.db import migrations, models

class Migration(migrations.Migration):
  dependencies = [
    ('merger', '0001_initial'),
  ]

  operations = [
    migrations.AddField(
      model_name='mergetask',
      name='progress',
      field=models.IntegerField(default=0),
    ),
  ]

--- ./merger/migrations/0003_mergetask_total_frames.py ---

from django.db import migrations, models

class Migration(migrations.Migration):
  dependencies = [
    ('merger', '0002_mergetask_progress'),
  ]

  operations = [
    migrations.AddField(
      model_name='mergetask',
      name='total_frames',
      field=models.IntegerField(default=0),
    ),
  ]

--- ./merger/migrations/0001_initial.py ---

# Generated by Django 5.1.1 on 2024-11-02 08:35

from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='MergeTask',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('task_id', models.CharField(max_length=255)),
                ('status', models.CharField(default='processing', max_length=20)),
                ('short_video_path', models.JSONField(blank=True, null=True)),
                ('large_video_paths', models.JSONField(blank=True, null=True)),
                ('video_links', models.JSONField(blank=True, null=True)),
            ],
        ),
    ]

--- ./merger/urls.py ---

from django.urls import path
from . import views

app_name = 'merger'

urlpatterns = [
  path('', views.index, name='index'),
  path('upload/', views.upload_files, name='upload_files'),
  path('processing/<str:task_id>/', views.processing, name='processing'),
  path('get_progress/<str:task_id>', views.get_progress, name='get_progress'),
  path(
    'check_status/<str:task_id>/', views.check_task_status, name='check_status'
  ),
  path('download_zip/<str:task_id>/', views.download_zip, name='download_zip'),
  path(
    'download_output/<path:videopath>/',
    views.download_video,
    name='download_output'
  ),
  path(
    'processing_successful/<str:task_id>/',
    views.processing_successful,
    name='processing_successful'
  ),
]

--- ./merger/models.py ---

from django.db import models

class MergeTask(models.Model):
  task_id = models.CharField(max_length=255)
  status = models.CharField(max_length=20, default='processing')
  short_video_path = models.JSONField(null=True, blank=True)
  large_video_paths = models.JSONField(null=True, blank=True)
  video_links = models.JSONField(null=True, blank=True)
  total_frames_done = models.IntegerField(default=0)
  total_frames = models.IntegerField(default=0)

  def __str__(self) -> str:
    return self.status

--- ./merger/tests.py ---

from django.test import TestCase

# Create your tests here.

--- ./merger/forms.py ---

from django import forms
from django.forms import formset_factory

class VideoUploadForm(forms.Form):
    video = forms.FileField()
    

# VideoUploadFormSet = formset_factory(VideoUploadForm, extra=5)  # Adjust 'extra' as needed

--- ./merger/views.py ---

# merger/views.py

import os
import subprocess
import zipfile
import re
import io
import logging
import threading
from concurrent.futures import ThreadPoolExecutor
from django.urls import reverse
from django.conf import settings
from django.http import HttpResponse, FileResponse, JsonResponse
from django.shortcuts import redirect, render, get_object_or_404
from django.contrib import messages
from django.views.decorators.http import require_POST
from django.contrib.auth.decorators import login_required
from urllib.parse import unquote  # Corrected import

from .forms import VideoUploadForm
from .models import MergeTask

# Set up logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)

import uuid
from datetime import datetime

def generate_task_id():
    return str(uuid.uuid4())

def sanitize_filename(filename):
    """
    Removes or replaces characters that are unsafe for filenames.
    """
    # Replace spaces with underscores
    filename = filename.replace(' ', '_')
    # Remove any character that is not alphanumeric, underscore, hyphen, or dot
    filename = re.sub(r'[^\w\-_\.]', '', filename)
    return filename

def has_audio(video_file):
    """
    Check if the video file has an audio stream.
    """
    command = [
        "ffprobe", "-v", "error",
        "-select_streams", "a:0",
        "-show_entries", "stream=codec_type",
        "-of", "csv=p=0",
        video_file
    ]
    try:
        result = subprocess.run(
            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True
        )
        output = result.stdout.strip()
        return output == "audio"
    except subprocess.CalledProcessError as e:
        logging.error(f"FFprobe error when checking audio for {video_file}: {e.stderr.strip()}")
        return False

def ffprobe_get_frame_count(video_filepath):
    """
    Uses ffprobe to count the number of video frames in a video file.
    """
    command = [
        'ffprobe',
        '-v', 'error',
        '-select_streams', 'v:0',
        '-count_frames',
        '-show_entries', 'stream=nb_read_frames',
        '-of', 'csv=p=0',
        video_filepath,
    ]
    try:
        result = subprocess.run(
            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True
        )
        output = result.stdout.strip()
        if output.isdigit():
            return int(output)
        else:
            logging.error(f"Couldn't get frame count for {video_filepath}: {result.stderr.strip()}")
            return 0
    except subprocess.CalledProcessError as e:
        logging.error(f"FFprobe error for {video_filepath}: {e.stderr.strip()}")
        return 0

def check_video_format_resolution(video_file):
    """
    Uses ffprobe to retrieve the width and height of the first video stream.
    Ensures that both width and height are even numbers.
    """
    command = [
        "ffprobe", "-v", "error",
        "-select_streams", "v:0",
        "-show_entries", "stream=width,height",
        "-of", "csv=p=0:s=x",
        video_file
    ]
    try:
        result = subprocess.run(
            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True
        )
        output = result.stdout.strip().split('\n')
        resolutions = [line.strip() for line in output if 'x' in line and line.strip()]
        if resolutions:
            try:
                width_str, height_str = resolutions[0].split('x')[:2]
                width = int(width_str.strip())
                height = int(height_str.strip())
                # Ensure dimensions are even
                width = width if width % 2 == 0 else width + 1
                height = height if height % 2 == 0 else height + 1
                return width, height
            except ValueError as e:
                logging.error(f"Error parsing resolution: {resolutions[0]} - {e}")
                return None, None
        else:
            logging.error(f"Could not determine resolution for video: {video_file}")
            return None, None
    except subprocess.CalledProcessError as e:
        logging.error(f"FFprobe error for {video_file}: {e.stderr.strip()}")
        return None, None

def preprocess_video(input_file, output_file, reference_resolution=None, merge_task=None):
    """
    Preprocesses a video by scaling it to the reference resolution and ensuring consistent encoding.
    Ensures that the output dimensions are even and that audio streams are present.
    If the input video lacks an audio stream, adds a silent audio track.
    """
    logging.info(f"Preprocessing video: {input_file}")

    # Check if the input video has an audio stream
    input_has_audio = has_audio(input_file)

    if input_has_audio:
        # Video with audio: scale and encode
        command = ["ffmpeg", "-y", "-i", input_file]

        if reference_resolution:
            width, height = reference_resolution
            # Scale with aspect ratio preservation and enforce even dimensions
            vf_filter = (
                f"scale={width}:{height}:force_original_aspect_ratio=decrease,"
                f"pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,"
                f"format=yuv420p"
            )
            command += ["-vf", vf_filter]

        # Ensure audio is encoded
        command += [
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-c:a", "aac",
            "-pix_fmt", "yuv420p",
            "-r", "30",  # Enforce frame rate
            output_file
        ]
    else:
        # Video without audio: add silent audio
        command = [
            "ffmpeg", "-y", "-i", input_file,
            "-f", "lavfi", "-i", "anullsrc=channel_layout=stereo:sample_rate=44100",
        ]

        if reference_resolution:
            width, height = reference_resolution
            vf_filter = (
                f"scale={width}:{height}:force_original_aspect_ratio=decrease,"
                f"pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,"
                f"format=yuv420p"
            )
            command += ["-vf", vf_filter]

        # Map video and silent audio
        command += [
            "-c:v", "libx264",
            "-preset", "ultrafast",
            "-c:a", "aac",
            "-shortest",
            "-pix_fmt", "yuv420p",
            "-r", "30",  # Enforce frame rate
            output_file
        ]

    logging.debug(f"Preprocess command: {' '.join(command)}")
    process = subprocess.Popen(
        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True
    )

    frames_processed = 0
    prev_frames_processed = 0
    while True:
        output = process.stderr.readline()
        if output == '' and process.poll() is not None:
            break
        if output:
            logging.debug(output.strip())
            match = re.search(r"frame=\s*(\d+)", output)
            if match:
                frames_processed = int(match.group(1))
                if frames_processed - prev_frames_processed >= 150:
                    if merge_task:
                        merge_task.total_frames_done += (frames_processed - prev_frames_processed)
                        merge_task.save()
                    prev_frames_processed = frames_processed

    return_code = process.wait()
    if return_code != 0:
        logging.error(f"FFmpeg failed during preprocessing of {input_file}. Check logs above for details.")
        # Remove the invalid output file if FFmpeg failed
        if os.path.exists(output_file):
            os.remove(output_file)
            logging.info(f"Removed invalid preprocessed file: {output_file}")
        return

    if merge_task:
        merge_task.total_frames_done += (frames_processed - prev_frames_processed)
        merge_task.save()

    logging.info(f"Finished preprocessing: {output_file}")

def concatenate_videos(input_files, output_file, merge_task):
    """
    Concatenates multiple video files into a single output file using FFmpeg's concat filter.
    """
    logging.info(f"Concatenating videos into: {output_file}")
    if len(input_files) < 2:
        logging.error("Need at least two files to concatenate")
        return

    # Build FFmpeg command with filter_complex 'concat'
    command = ['ffmpeg', '-y']
    for input_file in input_files:
        command += ['-i', input_file]

    # Construct the filter_complex string
    filter_complex = ""
    for i in range(len(input_files)):
        filter_complex += f"[{i}:v][{i}:a]"
    filter_complex += f"concat=n={len(input_files)}:v=1:a=1[outv][outa]"

    command += [
        '-filter_complex', filter_complex,
        '-map', '[outv]',
        '-map', '[outa]',
        '-c:v', 'libx264',
        '-preset', 'superfast',
        '-c:a', 'aac',
        '-pix_fmt', 'yuv420p',
        '-r', '30',
        output_file
    ]

    logging.debug(f"Concatenate command: {' '.join(command)}")
    process = subprocess.Popen(
        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True
    )

    frames_processed = 0
    prev_frames_processed = 0
    ffmpeg_error = ""
    while True:
        output = process.stderr.readline()
        if output == '' and process.poll() is not None:
            break
        if output:
            logging.debug(output.strip())
            ffmpeg_error += output
            match = re.search(r"frame=\s*(\d+)", output)
            if match:
                frames_processed = int(match.group(1))
                if frames_processed - prev_frames_processed >= 150:
                    if merge_task:
                        merge_task.total_frames_done += (frames_processed - prev_frames_processed)
                        merge_task.save()
                    prev_frames_processed = frames_processed

    return_code = process.wait()
    if return_code != 0:
        logging.error(f"FFmpeg failed during concatenation of {output_file}.")
        logging.error(f"FFmpeg error output: {ffmpeg_error}")
        # Remove the invalid output file if FFmpeg failed
        if os.path.exists(output_file):
            os.remove(output_file)
            logging.info(f"Removed invalid concatenated file: {output_file}")
        return

    if merge_task:
        merge_task.total_frames_done += (frames_processed - prev_frames_processed)
        merge_task.save()

    logging.info(f"Finished concatenating: {output_file}")

def process_videos(task_id):
    """
    Orchestrates the preprocessing and concatenation of videos for a given task.
    """
    logging.info("Starting video processing...")

    try:
        merge_task = MergeTask.objects.get(task_id=task_id)
    except MergeTask.DoesNotExist:
        logging.error(f"MergeTask with task_id {task_id} does not exist.")
        return

    short_videos = merge_task.short_video_path
    large_videos = merge_task.large_video_paths

    if not large_videos:
        logging.error("No large videos found for merging.")
        merge_task.status = 'failed'
        merge_task.save()
        return

    # Determine reference resolution from the first large video
    ref_resolution = check_video_format_resolution(large_videos[0])
    if not ref_resolution or not ref_resolution[0] or not ref_resolution[1]:
        logging.error("Invalid reference resolution. Cannot preprocess videos.")
        merge_task.status = 'failed'
        merge_task.save()
        return

    reference_resolution = ref_resolution
    logging.info(f"Reference resolution: {reference_resolution}")

    # Preprocess short videos
    preprocessed_short_files = []
    short_video_names = []
    with ThreadPoolExecutor() as executor:
        futures = []
        for video in short_videos:
            short_name = os.path.splitext(os.path.basename(video))[0]
            short_video_names.append(short_name)
            preprocessed_filename = f"preprocessed_{os.path.basename(video)}"
            output_file = os.path.join(settings.OUTPUT_FOLDER, preprocessed_filename)
            futures.append(executor.submit(preprocess_video, video, output_file, reference_resolution, merge_task))
            preprocessed_short_files.append(output_file)

        for future in futures:
            try:
                future.result()
            except Exception as e:
                logging.error(f"Error during preprocessing: {e}")
                merge_task.status = 'failed'
                merge_task.save()
                return

    # Preprocess large videos
    preprocessed_large_files = []
    large_video_names = []
    with ThreadPoolExecutor() as executor:
        futures = []
        for video in large_videos:
            large_name = os.path.splitext(os.path.basename(video))[0]
            large_video_names.append(large_name)
            preprocessed_filename = f"preprocessed_{os.path.basename(video)}"
            output_file = os.path.join(settings.OUTPUT_FOLDER, preprocessed_filename)
            futures.append(executor.submit(preprocess_video, video, output_file, reference_resolution, merge_task))
            preprocessed_large_files.append(output_file)

        for future in futures:
            try:
                future.result()
            except Exception as e:
                logging.error(f"Error during preprocessing: {e}")
                merge_task.status = 'failed'
                merge_task.save()
                return

    # Validate that preprocessed videos have video and audio streams
    valid_preprocessed_short_files = []
    valid_short_names = []
    for pre_file, sname in zip(preprocessed_short_files, short_video_names):
        w, h = check_video_format_resolution(pre_file)
        if w and h:
            valid_preprocessed_short_files.append(pre_file)
            valid_short_names.append(sname)
        else:
            logging.error(f"Preprocessed file {pre_file} does not contain a valid video stream.")

    if not valid_preprocessed_short_files:
        logging.error("No valid preprocessed short videos available for concatenation.")
        merge_task.status = 'failed'
        merge_task.save()
        return

    valid_preprocessed_large_files = []
    valid_large_names = []
    for pre_file, lname in zip(preprocessed_large_files, large_video_names):
        w, h = check_video_format_resolution(pre_file)
        if w and h:
            valid_preprocessed_large_files.append(pre_file)
            valid_large_names.append(lname)
        else:
            logging.error(f"Preprocessed file {pre_file} does not contain a valid video stream.")

    if not valid_preprocessed_large_files:
        logging.error("No valid preprocessed large videos available for concatenation.")
        merge_task.status = 'failed'
        merge_task.save()
        return

    # Now, concatenate each preprocessed short video with each preprocessed large video
    final_output_files = []
    with ThreadPoolExecutor() as executor:
        concat_futures = []
        for large_video, large_name in zip(valid_preprocessed_large_files, valid_large_names):
            # Concatenate each short video with the large video
            for short_file, sname in zip(valid_preprocessed_short_files, valid_short_names):
                # Remove 'preprocessed_' prefix for naming
                short_base = os.path.splitext(os.path.basename(short_file))[0].replace('preprocessed_', '')
                large_base = os.path.splitext(os.path.basename(large_video))[0].replace('preprocessed_', '')
                final_output_name = f"{short_base}_{large_base}.mp4"
                final_output = os.path.join(settings.OUTPUT_FOLDER, final_output_name)
                concat_futures.append(
                    executor.submit(concatenate_videos, [short_file, large_video], final_output, merge_task)
                )

                # Store relative paths
                relative_output = os.path.relpath(final_output, settings.MEDIA_ROOT)
                final_output_files.append({
                    'video_link': relative_output.replace('\\', '/'),  # Ensure URL-friendly paths
                    'file_name': final_output_name
                })

        for future in concat_futures:
            try:
                future.result()
            except Exception as e:
                logging.error(f"Error during concatenation: {e}")
                merge_task.status = 'failed'
                merge_task.save()
                return

    logging.info("Video processing complete!")
    merge_task.status = 'completed'
    merge_task.video_links = final_output_files
    merge_task.save()

@login_required
def index(request):
    """
    Renders the video upload form.
    """
    form = VideoUploadForm()
    return render(request, 'merger/index.html', {'form': form})

@require_POST
@login_required
def upload_files(request):
    """
    Handles the upload of short and large videos.
    """
    # Validate file sizes
    max_upload_size = getattr(settings, 'FILE_UPLOAD_MAX_MEMORY_SIZE', 10485760)  # Default 10MB
    for file in request.FILES.getlist('large_videos'):
        if file.size > max_upload_size:
            messages.error(request, "One of the large videos exceeds the maximum allowed size.")
            return redirect(reverse('merger:index'))

    task_id = generate_task_id()
    logging.info(f'Merge Task ID generated --> {task_id}')

    MergeTask.objects.create(task_id=task_id, status='processing')
    logging.info(f'A Merge Task object created for merge task id --> {task_id}')

    short_videos = request.FILES.getlist('short_videos')
    large_videos = request.FILES.getlist('large_videos')

    logging.info(f'Short videos uploaded: {short_videos}')
    logging.info(f'Large videos uploaded: {large_videos}')

    short_video_paths = []
    large_video_paths = []

    # Create a task-specific upload directory
    task_upload_dir = os.path.join(settings.UPLOAD_FOLDER, task_id)
    os.makedirs(task_upload_dir, exist_ok=True)

    # Save uploaded short videos
    for file in short_videos:
        original_filename = sanitize_filename(file.name)
        file_path = os.path.join(task_upload_dir, original_filename)
        try:
            with open(file_path, 'wb+') as destination:
                for chunk in file.chunks():
                    destination.write(chunk)
            short_video_paths.append(file_path)
        except Exception as e:
            logging.error(f"Error saving short video {original_filename}: {e}")
            messages.error(request, f"Error saving short video {original_filename}.")
            return redirect(reverse('merger:index'))

    # Save uploaded large videos
    for file in large_videos:
        original_filename = sanitize_filename(file.name)
        file_path = os.path.join(task_upload_dir, original_filename)
        try:
            with open(file_path, 'wb+') as destination:
                for chunk in file.chunks():
                    destination.write(chunk)
            large_video_paths.append(file_path)
        except Exception as e:
            logging.error(f"Error saving large video {original_filename}: {e}")
            messages.error(request, f"Error saving large video {original_filename}.")
            return redirect(reverse('merger:index'))

    logging.info(f'Short video paths: {short_video_paths}')
    logging.info(f'Large video paths: {large_video_paths}')

    merge_task = MergeTask.objects.get(task_id=task_id)
    merge_task.short_video_path = short_video_paths
    merge_task.large_video_paths = large_video_paths
    merge_task.save()

    # Calculate total frames for progress tracking
    total_short_video_frames = sum(ffprobe_get_frame_count(path) for path in short_video_paths)
    total_long_video_frames = sum(ffprobe_get_frame_count(path) for path in large_video_paths)
    total_frames = total_short_video_frames + (len(large_videos) * total_short_video_frames) + (len(short_videos) * total_long_video_frames)
    merge_task.total_frames = total_frames if total_frames > 0 else 1
    merge_task.save()

    return JsonResponse({'taskId': task_id})

@login_required
def processing(request, task_id):
    """
    Initiates the video processing in a separate thread.
    """
    try:
        merge_task = MergeTask.objects.get(task_id=task_id)
    except MergeTask.DoesNotExist:
        return HttpResponse("Task not found.", status=404)

    merge_credits_used = len(merge_task.short_video_path)
    if request.user.subscription.merge_credits < merge_credits_used:
        return HttpResponse(
            "You don't have enough merge credits, buy and try again!", status=403
        )

    thread = threading.Thread(target=process_videos, args=(task_id,))
    thread.start()

    # Deduct merge credits
    request.user.subscription.merge_credits -= merge_credits_used
    request.user.subscription.save()
    logging.info(f"Used {merge_credits_used} merge credits")

    return render(request, 'merger/processing.html', {'task_id': task_id})

@login_required
def get_progress(request, task_id):
    """
    Returns the progress of the video processing task.
    """
    merge_task = get_object_or_404(MergeTask, task_id=task_id)
    if merge_task.total_frames == 0:
        progress = 0
    else:
        progress = int(min(1, (merge_task.total_frames_done / merge_task.total_frames)) * 100)

    return JsonResponse({'progress': progress})

@login_required
def check_task_status(request, task_id):
    """
    Returns the status of the video processing task along with video links if completed.
    """
    task = get_object_or_404(MergeTask, task_id=task_id)
    return JsonResponse({
        'status': task.status,
        'video_links': task.video_links if task.status == 'completed' else None
    })

@login_required
def processing_successful(request, task_id):
    """
    Renders a success page with links to the processed videos.
    """
    task = get_object_or_404(MergeTask, task_id=task_id)
    return render(
        request, 'merger/processing_successful.html', {
            'task_id': task_id,
            'video_links': task.video_links
        }
    )

@login_required
def download_video(request, videopath):
    """
    Serves the requested video file as a download.
    """
    # Decode URL-encoded path
    videopath = unquote(videopath)

    # Construct the absolute path
    absolute_path = os.path.join(settings.MEDIA_ROOT, videopath)

    # Normalize the path to prevent directory traversal
    absolute_path = os.path.normpath(absolute_path)

    # Ensure the absolute_path is within MEDIA_ROOT
    if not absolute_path.startswith(os.path.abspath(settings.MEDIA_ROOT)):
        logging.warning(f"Attempted directory traversal attack: {absolute_path}")
        return HttpResponse("Invalid file path.", status=400)

    # Check if the video file exists
    if not os.path.exists(absolute_path):
        logging.warning(f"Video file not found: {absolute_path}")
        return HttpResponse("Video not found.", status=404)

    # Return the file as a download
    try:
        response = FileResponse(open(absolute_path, 'rb'), content_type='video/mp4')
        response['Content-Disposition'] = f'attachment; filename="{os.path.basename(absolute_path)}"'
        return response
    except Exception as e:
        logging.error(f"Error serving file {absolute_path}: {e}")
        return HttpResponse("Error serving the file.", status=500)

@login_required
def download_zip(request, task_id):
    """
    Creates and serves a ZIP archive of all processed videos for a given task.
    """
    task = get_object_or_404(MergeTask, task_id=task_id)
    videos = task.video_links or []

    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
        for video in videos:
            video_link = video.get('video_link')
            if video_link:
                absolute_video_path = os.path.join(settings.MEDIA_ROOT, video_link)
                if os.path.exists(absolute_video_path):
                    file_name = os.path.basename(absolute_video_path)
                    try:
                        zip_file.write(absolute_video_path, file_name)
                    except Exception as e:
                        logging.error(f"Error adding {absolute_video_path} to zip: {e}")
                else:
                    logging.warning(f"Video file for zipping not found: {absolute_video_path}")

    zip_buffer.seek(0)
    response = HttpResponse(zip_buffer, content_type='application/zip')
    response['Content-Disposition'] = 'attachment; filename="final_videos.zip"'
    return response
--- ./hooks/__init__.py ---


--- ./hooks/tools/video_processors.py ---

# Utility functions used in video processing
import logging
import os
import re
import shutil
from moviepy.editor import VideoFileClip, TextClip, ColorClip, CompositeVideoClip, ImageClip, concatenate_videoclips
from moviepy.video.fx.all import crop
from .utils import split_hook_text
from .font_utils import setup_fontconfig
import numpy as np
from django.conf import settings

logging.basicConfig(level=logging.DEBUG)

def crop_to_aspect_ratio(video_clip, target_width, target_height):
  original_width, original_height = video_clip.size
  target_aspect_ratio = target_width / target_height
  original_aspect_ratio = original_width / original_height

  if original_aspect_ratio > target_aspect_ratio:
    # Crop width to match the target aspect ratio
    new_width = int(target_aspect_ratio * original_height)
    x_center = original_width / 2
    x1 = int(x_center - new_width/2)
    x2 = int(x_center + new_width/2)
    y1, y2 = 0, original_height
  else:
    # Crop height to match the target aspect ratio
    new_height = int(original_width / target_aspect_ratio)
    y_center = original_height / 2
    y1 = int(y_center - new_height/2)
    y2 = int(y_center + new_height/2)
    x1, x2 = 0, original_width

  # Crop the video to the desired aspect ratio
  cropped_clip = crop(video_clip, x1=x1, y1=y1, x2=x2, y2=y2)

  # If the cropped video is not the exact target size, resize without distorting the video
  if cropped_clip.size != (target_width, target_height):
    cropped_clip = cropped_clip.resize((target_width, target_height))

  return cropped_clip

def create_custom_text_clip(
  hook_text, OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT, top_box_color, text_color,
  font_size, word_color_data, is_tiktok
):
  try:
    orig_hook_text_parts = split_hook_text(hook_text)
    hook_text = ' '.join(
      [word['text'] for cell in word_color_data for word in cell]
    )
    hook_text_parts = split_hook_text(hook_text)
    logging.info(f"Hook text parts: {hook_text_parts}")
    x_multiplier = OUT_VIDEO_WIDTH / 360
    y_multiplier = OUT_VIDEO_HEIGHT / 450
    min_red_area_h = int(round(40 * y_multiplier))
    fontsize1 = int(round(15 * x_multiplier))
    if is_tiktok == 1:
      fontsize1 += 18
    if OUT_VIDEO_WIDTH == 1920 and OUT_VIDEO_HEIGHT == 1080:
      fontsize1 -= 20

    max_width = OUT_VIDEO_WIDTH - 100
    logging.info(f'Variables created successfully')
    x_margin = 5

    # Setup Fontconfig for custom font
    font_path = os.path.abspath(
      str(settings.BASE_DIR) + '/dependencies/fonts/mu.otf'
    )
    logging.info(f"Font path: {font_path}")
    temp_fontconfig_dir = setup_fontconfig(font_path)

    # Build Pango-formatted text string with color for each word for the first part only
    pango_text = ""
    word_index = 0
    char_index = 0
    words_in_first_part = hook_text_parts[0].split()
    text_clips_ = []
    orig_hook_first_part_text = re.sub(r'\s+', ' ', orig_hook_text_parts[0])
    for word_data in word_color_data:
      for word_info in word_data:
        word = word_info['text'].capitalize(
        )  # Capitalize the first letter of the word

        # Only add the word to pango_text if it is in the first part
        if word_index < len(
            words_in_first_part
        ) and word == words_in_first_part[word_index].capitalize():
          color = word_info['color']

          # Override the color only if it's not black
          if color == (0, 0, 0):
            color = text_color  # Use the front-end color if the color is black

          color_hex = "#{:02x}{:02x}{:02x}".format(*color)

          # Apply the font directly in Pango markup
          word_index += 1
          char_index += len(word)
          pango_text += f'<span font_desc="Mu Font {fontsize1}" foreground="{color_hex}">{word}</span>'

          if char_index < len(
              orig_hook_first_part_text
          ) and orig_hook_first_part_text[char_index] == ' ':
            pango_text += ' '
            char_index += 1
    logging.info(f"Pango-formatted text: {pango_text}")

    # Create the text clip with Pango-formatted text for the first part
    try:
      text_clip1 = TextClip(
        pango_text.strip(),  # Pango-formatted string with word colors
        size=(max_width, None),
        method='pango',  # Enable Pango markup
        fontsize=fontsize1,
        color='white',  # Default color, overridden by Pango markup
        align='center'
      )
      logging.info(f"Debug: Created TextClip with size: {text_clip1.size}")
    except Exception as e:
      logging.error(f"Error creating TextClip: {e}")
      raise

    # Get the dimensions of the first text clip
    text_clip1_w, text_clip1_h = text_clip1.size
    if text_clip1_h > (min_red_area_h - 10):
      min_red_area_h = text_clip1_h + 10

    # Create background clip for the first part
    bg_clip1 = ColorClip(
      size=(OUT_VIDEO_WIDTH, min_red_area_h), color=top_box_color
    )

    text_clip1_y_offset = (min_red_area_h-text_clip1_h) / 2

    if is_tiktok == 1:
      padding_top = 380
      bg_clip1 = ColorClip(
        size=(OUT_VIDEO_WIDTH, int(min_red_area_h + ((padding_top//2)))),
        color=top_box_color
      )
      text_clip1_y_offset += (padding_top / 2)
      min_red_area_h += (padding_top / 2)
      padding_left = 0
      padding_right = 0
      # Yeni video boyutlarını padding ile hesaplayın
      adjusted_width = OUT_VIDEO_WIDTH - padding_left - padding_right
      adjusted_height = OUT_VIDEO_HEIGHT

      # Klipleri CompositeVideoClip içinde konumlandırın
      final_clip = CompositeVideoClip(
        [
          bg_clip1.set_position(
            (padding_left, 0)
          ),  # Arka plan klibi padding ile yerleştiriyoruz
          text_clip1.set_position(
            ("center", text_clip1_y_offset)
          ),  # TextClip için yukarıdan padding ekliyoruz
        ],
        size=(OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT)
      )
    else:
      final_clip = CompositeVideoClip(
        [
          bg_clip1.set_position((0, 0)),
          text_clip1.set_position(("center", text_clip1_y_offset)),
        ],
        size=(OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT)
      )

    # Process the second part (after the hyphen) if it exists
    if len(hook_text_parts) > 1:
      min_white_area_h = int(round(30 * y_multiplier))
      fontsize2 = int(round(15 * 0.6 * x_multiplier))

      if is_tiktok == 1:
        fontsize2 += 18 * 0.6
      elif OUT_VIDEO_WIDTH == 1920 and OUT_VIDEO_HEIGHT == 1080:
        fontsize2 -= 20 * 0.6
      else:
        fontsize2 += 6
      second_part_text = hook_text_parts[1]

      # Build Pango-formatted text string with color for the second part
      pango_text2 = ""
      word_index_second = 0
      words_in_second_part = second_part_text.split()
      for word_info in word_data:
        word = word_info['text'].capitalize()

        # Ensure word is part of the second part
        if word_index_second < len(
            words_in_second_part
        ) and word == words_in_second_part[word_index_second].capitalize():
          color = word_info['color']
          if color == (255, 255, 255):
            color = (0, 0, 0)  # Use default color if the color is black

          color_hex = "#{:02x}{:02x}{:02x}".format(*color)

          pango_text2 += f'<span font_desc="Mu Font {fontsize2}" foreground="{color_hex}">{word}</span> '
          word_index_second += 1
      # Create TextClip for the second part with Pango-formatted text
      text_clip2 = TextClip(
        pango_text2.strip(),
        size=(OUT_VIDEO_WIDTH - (x_margin*2), 0),
        method='pango',  # Enable Pango markup
        fontsize=fontsize2,
        color='black',  # Default color, overridden by Pango markup
        align='center',
      )
      text_clip2_w, text_clip2_h = text_clip2.size
      if text_clip2_h > min_white_area_h:
        min_white_area_h = text_clip2_h

      # Create background clip for the second part
      bg_clip2 = ColorClip(
        size=(OUT_VIDEO_WIDTH, min_white_area_h), color=(255, 255, 255)
      )

      text_clip2_y_offset = min_red_area_h + (min_white_area_h-text_clip2_h) / 2

      final_clip = CompositeVideoClip(
        [
          bg_clip1.set_position((0, 0)),
          bg_clip2.set_position((0, min_red_area_h)),
          text_clip1.set_position(('center', text_clip1_y_offset)),
          text_clip2.set_position((x_margin, text_clip2_y_offset)),
        ],
        size=(OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT)
      )

    # Clean up the temporary Fontconfig directory
    try:
      shutil.rmtree(temp_fontconfig_dir)
    except Exception as err:
      logging.error(f"Error removing Fontconfig directory: {err}")

    return final_clip

  except Exception as e:
    logging.error(f"Error in create_custom_text_clip: {e}")
    raise

def process_audio_on_videos(
  row,
  video_files,
  idx,
  input_df,
  hook_number,
  hook_text,
  num_videos_to_use,
  audio_clip,
  OUT_VIDEO_WIDTH,
  OUT_VIDEO_HEIGHT,
  output_videos_folder,
  total_rows,
  task_id,
  top_box_color,
  default_text_color,
  word_color_data,
  audio_file=None,
  add_watermark=False,
  is_tiktok=False
):
  # Remove underscores from the hook text for display
  cleaned_hook_text = hook_text.replace('_', '')

  row['Input Video Filename'] = [
    os.path.basename(considered_video) for considered_video in video_files
  ]
  input_df.at[idx, 'Input Video Filename'] = row['Input Video Filename']

  # Ensure num_videos_to_use is valid and non-zero
  if num_videos_to_use <= 0:
    logging.error(
      f"num_videos_to_use is 0 or less for hook {hook_number}, setting it to 1 to avoid division by zero."
    )
    num_videos_to_use = 1

  each_video_duration = audio_clip.duration / num_videos_to_use
  video_clips = []
  logging.debug(
    f"Audio clip duration: {audio_clip.duration}, num_videos_to_use: {num_videos_to_use}"
  )

  for considered_vid in video_files:
    try:
      # Ensure the video file exists
      if not os.path.exists(considered_vid):
        logging.error(f"Video file {considered_vid} does not exist.")
        continue

      # Log and process the video
      logging.info(f'Processing video: {considered_vid}')
      video_clip = VideoFileClip(considered_vid).subclip(0, each_video_duration)

      # Check if the video clip has valid duration
      if video_clip.duration <= 0:
        logging.error(
          f"Video {considered_vid} has invalid duration {video_clip.duration}. Skipping."
        )
        continue

      # Apply cropping to maintain aspect ratio without distortion
      video_clip = crop_to_aspect_ratio(
        video_clip, OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT
      )

      # Add the clip to the list of video clips
      video_clips.append(video_clip)
    except Exception as e:
      logging.error(f"Error processing video {considered_vid}: {e}")
      continue

  # Ensure there are valid clips to concatenate
  if not video_clips:
    logging.error("No valid video clips were found for concatenation.")
    return None

  logging.info('Concatenating videos')
  final_video_clip = concatenate_videoclips(video_clips)
  logging.info('Concatenated videos')

  # Automatically adjust the font size based on video dimensions and text length
  auto_font_size = max(
    int(OUT_VIDEO_WIDTH / len(cleaned_hook_text) * 1.5), 20
  )  # Simple logic to adjust font size

  # Ensure correct word color data is used
  if idx < len(word_color_data):
    specific_word_color_data = word_color_data[idx]
  else:
    specific_word_color_data = [
    ]  # Fallback to an empty list if out of range (for safety)

  logging.info(f"Specific word color data: {specific_word_color_data}")
  # Pass specific_word_color_data to the custom text clip creation
  logging.info('Using the create_custom_text_clip method')
  custom_text_clip = create_custom_text_clip(
    cleaned_hook_text, OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT, top_box_color,
    default_text_color, auto_font_size, specific_word_color_data, is_tiktok
  )
  logging.info('Used the create_custom_text_clip method')

  logging.info('Adding watermark to final video')

  final_clip = None
  if add_watermark:
    watermark = ImageClip("hooks/tools/watermark.png")
    width = custom_text_clip.size[0] + 650
    height = width * (watermark.size[1] / watermark.size[0])
    watermark = watermark.resize(height=height, width=width)
    watermark = watermark.set_position("center").set_duration(
      final_video_clip.duration
    )

    logging.info('Creating a CompositeVideoClip instance')
    final_clip = CompositeVideoClip(
      [
        final_video_clip.audio_fadein(0.2).audio_fadeout(0.2),
        final_video_clip,
        custom_text_clip,
        watermark,
      ]
    ).set_audio(audio_clip).set_duration(audio_clip.duration)
    logging.info("Created a CompositeVideoClip instance")
  else:
    logging.info('Creating a CompositeVideoClip instance')
    final_clip = CompositeVideoClip(
      [
        final_video_clip.audio_fadein(0.2).audio_fadeout(0.2),
        final_video_clip,
        custom_text_clip,
      ]
    ).set_audio(audio_clip).set_duration(audio_clip.duration)
    logging.info("Created a CompositeVideoClip instance")

  output_video_filename = os.path.join(output_videos_folder, f'hook_{idx}.mp4')
  logging.info(f"{output_videos_folder},'---------->output_videos_folder")

  final_clip.write_videofile(
    output_video_filename,
    temp_audiofile=os.path.join(output_videos_folder, f"temp-audio_{idx}.m4a"),
    remove_temp=False,
    codec='libx264',
    audio_codec="aac"
  )

  logging.info(f"Video processing completed successfully")

--- ./hooks/tools/utils.py ---

# Small utility functions used in the hook app
import os
import shutil
import string
import random

def hex_to_rgb(hex_color):
    """Convert hex color to RGB tuple."""
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

def delete_temp_dir(temp_dir):
    try:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        print(f"Temporary directory {temp_dir} deleted successfully.")
    except Exception as e:
        print(f"Error deleting temporary directory {temp_dir}: {str(e)}")

def handle_task_cancellation(temp_dir, task_id):
    delete_temp_dir(temp_dir)

def split_hook_text(hook_text):
    words = hook_text.split()
    hook_text = ' '.join(word.capitalize() for word in words)

    if ' - ' in hook_text:
        last_dash_index = hook_text.rfind('-')
        line1 = hook_text[:last_dash_index].strip()
        line2 = hook_text[last_dash_index + 1:].strip()
        return [line1, line2]
    else:
        line1 = hook_text
        return [line1]
      
def generate_task_id():
    chars = string.ascii_letters + string.digits
    task_id = "task-"
    for _ in range(9):
        task_id += random.choice(chars)
    return task_id
--- ./hooks/tools/audio_processors.py ---

# Utility functions used to process audios
import os
import re
import requests
import logging

logging.basicConfig(level=logging.DEBUG)

def text_to_speech_file(api_key, text: str, save_file_path: str, voice_id: str, remove_punctuation: bool = True) -> bool:
    if remove_punctuation:
        text = text.replace('-', ' ').replace('"', ' ').replace("'", ' ')
        text = re.sub(r'[^\w\s]', '', text)

    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {
        "Accept": "audio/mpeg",
        "Content-Type": "application/json",
        "xi-api-key": api_key
    }
    data = {
        "text": text,
        "model_id": "eleven_monolingual_v1",
        "voice_settings": {
            "stability": 0.5,
            "similarity_boost": 0.75
        }
    }

    response = requests.post(url, json=data, headers=headers)

    if response.status_code != 200:
        logging.error(f"API request failed with status code {response.status_code}: {response.text}")
        raise Exception(f"API request failed with status code {response.status_code}")

    with open(save_file_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                f.write(chunk)

    return True, voice_id

def process_audios(api_key, row, hook_number, hook_text, input_df, idx, output_audios_folder, voice_id):
    print(voice_id)
    if row['Audio Filename'] in (None, '') or not os.path.exists(os.path.join(output_audios_folder, row['Audio Filename'])):
        logging.info(f"Generating voiceover for hook {hook_number}...")
        audio_filename = os.path.join(output_audios_folder, f'hook_{hook_number}.mp3')
        # import pdb;pdb.set_trace()
        try:
            status, voice_name = text_to_speech_file(api_key, hook_text, audio_filename, voice_id)
            row['Voice'] = voice_name
            row['Audio Filename'] = os.path.basename(audio_filename)
            input_df.at[idx, 'Voice'] = voice_name
            input_df.at[idx, 'Audio Filename'] = row['Audio Filename']
        except Exception as err:
            logging.error(f"Failed to hook audio file --> {audio_filename} --> {str(err)}", exc_info=True)

--- ./hooks/tools/spreadsheet_extractor.py ---

import re
import requests
import logging
from django.conf import settings

# setup logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Extract Spreadsheet ID
def extract_spreadsheet_id(google_sheet_link):
  """
    Extracts the spreadsheet ID from the Google Sheets URL.
    Raises a ValueError if the URL is invalid.
    """
  logger.info(f"Extracting spreadsheet ID from URL: {google_sheet_link}")
  match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', google_sheet_link)
  if match:
    spreadsheet_id = match.group(1)
    logger.debug(f"Spreadsheet ID extracted: {spreadsheet_id}")
    return spreadsheet_id
  else:
    logger.error("Invalid Google Sheets URL")
    raise ValueError("Invalid Google Sheets URL")

# Fetch Basic Google Sheet Data
def fetch_google_sheet_data(google_sheet_link):
  """
    Fetches basic data from a Google Sheet.
    """
  sheet_values = None

  try:
    spreadsheet_id = extract_spreadsheet_id(google_sheet_link)
    url = f"https://sheets.googleapis.com/v4/spreadsheets/{spreadsheet_id}/values:batchGet?ranges=Sheet1&key={settings.CREDENTIALS['GOOGLE_API_KEY']}"
    logger.info(f"Fetching data from URL: {url}")

    response = requests.get(url)
    response.raise_for_status()  # Raises an exception for 4xx/5xx responses

    data = response.json()
    sheet_values = data['valueRanges'][0].get('values', [])

    if len(sheet_values) == 0:
      logger.error(f"Empty Spreadsheet: {sheet_values}")
      raise Exception('Spreadsheet Is Empty')

    logger.debug(f"Data fetched: {sheet_values}")
    return sheet_values
  except requests.exceptions.RequestException as e:
    logger.error(f"Request failed: {e}")
    raise Exception(
      f"Spreadsheet Not Found, Make Sure It's Public Or Use Another Link"
    )
  except ValueError as ve:
    logger.error(f"Error extracting spreadsheet ID: {ve}")
    raise Exception(f"Your Spreadsheet ID Is Incorrect")
  except Exception as e:
    if sheet_values is not None and len(sheet_values) == 0:
      logger.error(f"Empty Spreadsheet: {sheet_values}")
      raise Exception('Spreadsheet Is Empty')

    logger.error(f"Unexpected error: {e}")
    raise Exception(f"Unexpected Error Happend, Please Try Again Later")

# Fetch data from Google Sheets API
def fetch_google_sheet_data_with_formatting(spreadsheet_id, api_key):
  url = (
    f'https://sheets.googleapis.com/v4/spreadsheets/{spreadsheet_id}'
    f'?fields=sheets.data.rowData.values.effectiveValue,sheets.data.rowData.values.textFormatRuns&key={api_key}'
  )

  try:
    response = requests.get(url)
    response.raise_for_status()
    return response.json()
  except requests.exceptions.RequestException as e:
    logger.error("Failed to fetch data from Google Sheets API: %s", str(e))
    raise

# Parse text and formatting from a cell
def parse_cell_text_and_format(cell):
  try:
    formatted_text = cell.get('effectiveValue', {}).get('stringValue', '')
    text_format_runs = cell.get('textFormatRuns', [])
    return formatted_text, text_format_runs
  except Exception as e:
    logger.error("Failed to parse cell data: %s", str(e))
    raise

# Convert color data from Google's API format to RGB tuple
def extract_color_from_run(run):
  try:
    foreground_color = run.get('format', {}).get('foregroundColor', {})
    color_rgb = (
      int(foreground_color.get('red', 0) * 255),
      int(foreground_color.get('green', 0) * 255),
      int(foreground_color.get('blue', 0) * 255)
    )
    return color_rgb
  except Exception as e:
    logger.warning("Error extracting color data from run: %s", str(e))
    return (0, 0, 0)  # Default to black if no color is found

# Process each text format run
def process_text_format_runs(formatted_text, text_format_runs):
  word_data = []
  last_index = 0

  if not text_format_runs:
    words = formatted_text.split()
    for word in words:
      word_data.append(
        {
          'text': word,
          'color': (0, 0, 0)
        }
      )  # Default color: black
    return word_data

  for i, run in enumerate(text_format_runs):
    start_index = run.get('startIndex', 0)
    end_index = text_format_runs[i + 1]['startIndex'] if i + 1 < len(
      text_format_runs
    ) else len(formatted_text)

    # Add unformatted text before the current run
    if start_index > last_index:
      pre_run_text = formatted_text[last_index:start_index]
      pre_run_words = pre_run_text.split()
      for word in pre_run_words:
        word_data.append(
          {
            'text': word,
            'color': (0, 0, 0)
          }
        )  # Default color: black

    # Add formatted text for the current run
    run_text = formatted_text[start_index:end_index]
    run_words = run_text.split()
    color_rgb = extract_color_from_run(run)

    for word in run_words:
      word_data.append({'text': word, 'color': color_rgb})

    last_index = end_index

  # Add any trailing text after the last run
  if last_index < len(formatted_text):
    trailing_text = formatted_text[last_index:]
    trailing_words = trailing_text.split()
    for word in trailing_words:
      word_data.append(
        {
          'text': word,
          'color': (0, 0, 0)
        }
      )  # Default color: black

  return word_data

# Process a single row of data from Google Sheets
def process_row(row):
  row_data = []
  for cell in row.get('values', []):
    try:
      formatted_text, text_format_runs = parse_cell_text_and_format(cell)
      word_data = process_text_format_runs(formatted_text, text_format_runs)
      row_data.append(word_data)
    except Exception as e:
      logger.warning("Error processing row data: %s", str(e))
      row_data.append(None)  # Add None if there's an error in processing
  return row_data

# Main function to fetch and process word color data
def extract_word_color_data(google_sheet_link):
  try:
    # Extract the spreadsheet ID from the URL
    api_key = settings.CREDENTIALS['GOOGLE_API_KEY']
    spreadsheet_id = extract_spreadsheet_id(google_sheet_link)

    # Fetch data from Google Sheets API
    data = fetch_google_sheet_data_with_formatting(spreadsheet_id, api_key)
    rows = data['sheets'][0]['data'][0]['rowData']

    # Process each row
    sheet_data = []
    for row in rows:
      row_data = process_row(row)
      sheet_data.append(row_data)

    logger.info("Successfully fetched and processed word color data")
    return sheet_data

  except Exception as e:
    logger.error("Failed to fetch and process word color data: %s", str(e))
    return None

--- ./hooks/tools/font_utils.py ---

# Utility functions used to process fonts
import logging
import tempfile
import os
import subprocess

logging.basicConfig(level=logging.basicConfig)

def setup_fontconfig(font_path):
    # Step 1: Create a temporary directory
    temp_dir = tempfile.mkdtemp()
    logging.info(f"Created temporary directory at {temp_dir}")

    # Step 2: Prepare the Fontconfig configuration content
    fontconfig_content = f"""<?xml version="1.0"?>
<!DOCTYPE fontconfig SYSTEM "fonts.dtd">
<fontconfig>
    <dir>{os.path.dirname(font_path)}</dir>
    <match target="pattern">
        <test name="family" qual="any">
            <string>Mu Font</string>
        </test>
        <edit name="family" mode="assign" binding="strong">
            <string>Mu Font</string>
        </edit>
        <edit name="file" mode="assign" binding="strong">
            <string>{font_path}</string>
        </edit>
    </match>
</fontconfig>
"""
    logging.info("Fontconfig content prepared:")
    logging.info(fontconfig_content)

    # Step 3: Write the configuration to the temporary directory
    config_path = os.path.join(temp_dir, "fonts.conf")
    with open(config_path, "w") as f:
        f.write(fontconfig_content.strip())  # Ensure no leading/trailing spaces or newlines
    logging.info(f"Fontconfig written to {config_path}")

    # Step 4: Set the FONTCONFIG_FILE environment variable
    os.environ["FONTCONFIG_FILE"] = config_path
    logging.info(f"FONTCONFIG_FILE environment variable set to {config_path}")

    # Step 5: Verify the setup by listing the fonts recognized by Fontconfig
    result = subprocess.run(['fc-list'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    logging.info("Fontconfig available fonts after setup:")
    logging.info(result.stdout.decode())
    
    # Step 6: Check if any errors were reported
    if result.stderr:
        print("Debug: Fontconfig error:")
        print(result.stderr.decode())

    return temp_dir
--- ./hooks/tools/processor.py ---

import logging
import os
import subprocess
import threading

from tqdm import tqdm
import pandas as pd
from moviepy.editor import AudioFileClip

from django.core.cache import cache
from django.http import JsonResponse

from hooks.models import Hook

from .utils import hex_to_rgb, handle_task_cancellation, delete_temp_dir
from .spreadsheet_extractor import fetch_google_sheet_data, extract_word_color_data
from .audio_processors import process_audios
from .video_processors import process_audio_on_videos

from hooks.models import Task

logging.basicConfig(level=logging.DEBUG)
canceled_tasks = set()

def process(params):
  task_id = params.get('task_id', None)
  try:
    input_df = params['input_df']
    if 'Hook Text' not in input_df.columns:
      raise Exception("The column 'Hook Text' does not exist in the DataFrame.")

    google_sheet_link = params.get('google_sheet_link')
    if not google_sheet_link:
      raise Exception("Missing 'google_sheet_link' in params.")

    word_color_data = extract_word_color_data(google_sheet_link)

    for idx, row in input_df.iterrows():
      hook_text = row['Hook Text']

    ELEVENLABS_API_KEY = params['api_key']
    no_of_parallel_executions = params['parallel_processing']

    INPUT_DIR = params['input_dir']
    OUTPUT_DIR = params['output_dir']
    voice_id = params['voice_id']
    temp_dir = params['temp_dir']
    top_box_color = params['top_box_color']
    default_text_color = params['default_text_color']

    input_videos_folder = os.path.join(INPUT_DIR, 'video')
    output_audios_folder = os.path.join(OUTPUT_DIR, 'audios')
    output_videos_folder = os.path.join(OUTPUT_DIR, 'videos')
    is_tiktok = 0
    if params['aspect_ratio'] == 'option1':
      OUT_VIDEO_DIM = "1080x1080"
    elif params['aspect_ratio'] == 'option2':
      OUT_VIDEO_DIM = "1080x1350"
    elif params['aspect_ratio'] == 'option3':
      OUT_VIDEO_DIM = "1080x1920"
      is_tiktok = 1
    elif params['aspect_ratio'] == 'option4':
      OUT_VIDEO_DIM = "1920x1080"
    else:
      raise ValueError(f"Unsupported aspect ratio: {params['aspect_ratio']}")

    OUT_VIDEO_HEIGHT = int(OUT_VIDEO_DIM.split('x')[1])
    OUT_VIDEO_WIDTH = int(OUT_VIDEO_DIM.split('x')[0])

    if len(os.listdir(input_videos_folder)) == 0:
      raise Exception(
        f"input/videos folder {input_videos_folder} does not contain any videos"
      )
    video_files = sorted(
      [
        f for f in os.listdir(input_videos_folder)
        if f.endswith('.mp4') or f.endswith('.mov')
      ]
    )

    for col in ["Hook Video Filename", "Input Video Filename", "Audio Filename",
                "Voice"]:
      if col not in input_df.columns:
        input_df[col] = ''

    l_unprocessed_rows = len(input_df[input_df['Hook Video Filename'] == ''])

    all_hooks = []
    total_rows = len(input_df)
    current_row = 0

    for idx_1, row in tqdm(input_df.iterrows(), total=total_rows,
                           desc="Processing rows"):
      hook_text = row['Hook Text']
      hook_number = idx_1 + 1

      process_audios(
        ELEVENLABS_API_KEY, row, hook_number, hook_text, input_df, idx_1,
        output_audios_folder, voice_id
      )
      logging.info('Audio proccessed successfully')

    current_thread_count = 0

    for idx, row in tqdm(input_df.iterrows(), total=total_rows,
                         desc="Processing rows"):
      hook_text = row['Hook Text']
      hook_number = idx + 1

      audio_clip = AudioFileClip(
        os.path.join(output_audios_folder, row['Audio Filename'])
      )
      video_index = idx % len(video_files)
      num_videos_to_use = int(round(audio_clip.duration / 2))

      video_file_size = len(video_files)
      if num_videos_to_use + video_index > video_file_size:
        num_videos_to_use = video_file_size - video_index

      last_video = video_index + num_videos_to_use
      video_files_to_use = [
        os.path.join(input_videos_folder, video_files[i])
        for i in range(video_index, last_video)
      ]

      if params['task_id'] in canceled_tasks:
        return handle_task_cancellation(temp_dir, task_id)

      hook_job = threading.Thread(
        target=process_audio_on_videos,
        args=(
          row, video_files_to_use, idx, input_df, hook_number, hook_text,
          num_videos_to_use, audio_clip, OUT_VIDEO_WIDTH, OUT_VIDEO_HEIGHT,
          output_videos_folder, total_rows, task_id, top_box_color,
          default_text_color, word_color_data, None, params['add_watermark'],
          is_tiktok
        )
      )
      hook_job.start()
      all_hooks.append(hook_job)
      current_thread_count += 1
      if current_thread_count == int(no_of_parallel_executions):
        for hook in all_hooks:
          hook.join()
        all_hooks.clear()
        current_thread_count = 0
    for hook in all_hooks:
      try:
        hook.join()
      except Exception as err:
        logging.error(f'failed to join all hooks --> {str(err)}')

    # Now generate the video links after all processing is complete
    credits_used = 0
    video_links = []
    for idx, row in input_df.iterrows():
      logging.info('Trying to generate link')
      row['Hook Video Filename'] = f'hook_{idx}.mp4'
      video_path = os.path.join(
        output_videos_folder, row['Hook Video Filename']
      )
      video_links.append(
        {
          'file_name': row['Hook Video Filename'],
          'video_link': video_path
        }
      )
      credits_used += 1
      logging.info("used one credit")
      logging.info(
        f"Generated video link with file name: {row['Hook Video Filename']}"
      )

    logging.info(f"Task {task_id} completed.")
    return video_links, credits_used

  except Exception as e:
    logging.error(f"Error during processing ---> {str(e)}")
    delete_temp_dir(params.get('temp_dir', ''))

def process_files(
  temp_dir, task_id, add_watermark=False, aspect_ratio='option1'
):

  hook_object = Hook.objects.filter(task_id=task_id).first()
  if not hook_object:
    return JsonResponse({"error": "Invalid Task id"})

  # Extract necessary fields from the object
  video_files = hook_object.hooks_content
  google_sheet_link = hook_object.google_sheets_link
  voice_id = hook_object.voice_id
  api_key = hook_object.eleven_labs_api_key
  parallel_processing = hook_object.parallel_processing
  top_box_color_value = hook_object.box_color
  main_box_color_value = hook_object.font_color

  # Convert hex colors to RGB
  top_box_color = hex_to_rgb(top_box_color_value)
  default_text_color = hex_to_rgb(main_box_color_value)

  if not video_files or not google_sheet_link or not voice_id or not api_key or not parallel_processing:
    return JsonResponse({"error": "Missing form data"})

  # Create directories for input/output files
  input_videos_folder = os.path.join(temp_dir, 'input', 'video')
  output_audios_folder = os.path.join(temp_dir, 'output', 'audios')
  output_videos_folder = os.path.join(temp_dir, 'output', 'videos')

  # Ensure the directories exist
  os.makedirs(input_videos_folder, exist_ok=True)
  os.makedirs(output_audios_folder, exist_ok=True)
  os.makedirs(output_videos_folder, exist_ok=True)

  # Save the video file
  video_files_paths = []
  video_file_name = os.path.basename(video_files.name)
  video_file_path = os.path.join(input_videos_folder, video_file_name)
  os.makedirs(os.path.dirname(video_file_path), exist_ok=True)
  with open(video_file_path, 'wb+') as destination:
    for chunk in video_files.chunks():
      destination.write(chunk)
  video_files_paths.append(video_file_path)

  # Fetch the data from Google Sheets
  google_sheet_data = fetch_google_sheet_data(google_sheet_link)
  extract_word_color_data(google_sheet_link)
  input_df = pd.DataFrame(google_sheet_data)
  if input_df.empty or ('Hook Text' not in input_df.columns
                        and input_df.shape[1] > 0):
    if input_df.shape[1] == 1:
      input_df.columns = ['Hook Text']
    else:
      return JsonResponse(
        {
          "error":
            "Ensure the google sheet access is updated to anyone with link."
        }
      )

  # Create a params dictionary to pass to the background task
  params = {
    "input_dir": os.path.join(temp_dir, 'input'),
    "output_dir": os.path.join(temp_dir, 'output'),
    "video_files_paths": video_files_paths,
    "voice_id": voice_id,
    "api_key": api_key,
    "parallel_processing": parallel_processing,
    "task_id": task_id,
    "temp_dir": temp_dir,
    "top_box_color": top_box_color,
    "default_text_color": default_text_color,
    "input_df": input_df,
    "google_sheet_link": google_sheet_link,
    "add_watermark": add_watermark,
    "aspect_ratio": aspect_ratio,
  }
  cache.set(task_id, temp_dir, timeout=600)

  video_links, credits_used = process(params)
  return video_links, credits_used

--- ./hooks/apps.py ---

from django.apps import AppConfig


class HooksConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'hooks'

--- ./hooks/admin.py ---

from django.contrib import admin
from .models import Hook, Task

# Register your models here.
@admin.register(Hook)
class HookAdmin(admin.ModelAdmin):
    list_display = ['hooks_content', 'google_sheets_link',
                    'eleven_labs_api_key', 'voice_id']
    
@admin.register(Task)
class TaskAdmin(admin.ModelAdmin):
    list_display = ['task_id', 'status', 'video_links']
--- ./hooks/migrations/__init__.py ---


--- ./hooks/migrations/0003_alter_hook_hooks_content.py ---

import hooks.models
from django.db import migrations, models

class Migration(migrations.Migration):
  dependencies = [
    ('hooks', '0002_hook_dimension_task_aspect_ratio'),
  ]

  operations = [
    migrations.AlterField(
      model_name='hook',
      name='hooks_content',
      field=models.FileField(
        blank=True,
        max_length=1073741824,
        null=True,
        upload_to='hooks_videos/',
        validators=[hooks.models.validate_video_file]
      ),
    ),
  ]

--- ./hooks/migrations/0002_hook_dimension_task_aspect_ratio.py ---

# Generated by Django 5.1.1 on 2024-11-04 21:31

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('hooks', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='hook',
            name='dimension',
            field=models.CharField(choices=[('option1', 'option1'), ('option2', 'option2'), ('option3', 'option3'), ('option4', 'option4')], default='option1', max_length=30),
        ),
        migrations.AddField(
            model_name='task',
            name='aspect_ratio',
            field=models.CharField(default='option1', max_length=255),
        ),
    ]

--- ./hooks/migrations/0004_alter_hook_hooks_content.py ---

import hooks.models
from django.db import migrations, models

class Migration(migrations.Migration):
  dependencies = [
    ('hooks', '0003_alter_hook_hooks_content'),
  ]

  operations = [
    migrations.AlterField(
      model_name='hook',
      name='hooks_content',
      field=models.FileField(
        blank=True,
        max_length=500,
        null=True,
        upload_to='hooks_videos/',
        validators=[hooks.models.validate_video_file]
      ),
    ),
  ]

--- ./hooks/migrations/0001_initial.py ---

# Generated by Django 5.1.1 on 2024-11-02 08:35

import hooks.models
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Hook',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('hooks_content', models.FileField(blank=True, max_length=500, null=True, upload_to='hooks_videos/', validators=[hooks.models.validate_video_file])),
                ('google_sheets_link', models.URLField(blank=True, max_length=500, null=True)),
                ('eleven_labs_api_key', models.CharField(blank=True, max_length=255, null=True)),
                ('voice_id', models.CharField(blank=True, max_length=255, null=True)),
                ('box_color', models.CharField(default='#485AFF', max_length=7)),
                ('font_color', models.CharField(default='#FFFFFF', max_length=7)),
                ('task_id', models.CharField(max_length=1000, unique=True)),
                ('parallel_processing', models.BooleanField(default=False)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name='Package',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=100)),
                ('price', models.PositiveIntegerField()),
                ('stripe_id', models.CharField(max_length=200)),
                ('video_limit', models.PositiveIntegerField()),
                ('price_per_video', models.FloatField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='Task',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('task_id', models.CharField(max_length=255)),
                ('status', models.CharField(default='processing', max_length=20)),
                ('video_links', models.JSONField(blank=True, null=True)),
            ],
        ),
    ]

--- ./hooks/urls.py ---

from django.urls import path
from . import views

app_name = 'hooks'

urlpatterns = [
  path('upload/', views.upload_hook, name='upload'),
  path(
    'processing/<str:task_id>/<str:aspect_ratio>/',
    views.processing,
    name='processing'
  ),
  path(
    'check_status/<str:task_id>/', views.check_task_status, name='check_status'
  ),
  path('download_zip/<str:task_id>/', views.download_zip, name='download_zip'),
  path(
    'download_output/<path:videopath>/',
    views.download_video,
    name='download_output'
  ),
  path(
    'processing_successful/<str:task_id>/',
    views.processing_successful,
    name='processing_successful'
  ),
  path(
    'validate-google-sheet-link/',
    views.validate_google_sheet_link,
    name='validate_google_sheet_link'
  ),
  path('validate-api-key/', views.validate_api_key, name='validate_api_key'),
]

--- ./hooks/models.py ---

from django.db import models
from django.core.exceptions import ValidationError

def validate_video_file(value):
  # List of allowed video mime types
  valid_mime_types = [
    'video/mp4', 'video/x-m4v', 'video/quicktime', 'video/x-msvideo',
    'video/x-ms-wmv'
  ]
  file_mime_type = value.file.content_type

  if file_mime_type not in valid_mime_types:
    raise ValidationError(
      f'Unsupported file type: {file_mime_type}. Please upload a valid video file.'
    )

class Hook(models.Model):
  hooks_content = models.FileField(
    max_length=500,
    upload_to='hooks_videos/',
    blank=True,
    null=True,
    validators=[validate_video_file]
  )
  google_sheets_link = models.URLField(max_length=500, blank=True, null=True)
  eleven_labs_api_key = models.CharField(max_length=255, blank=True, null=True)
  voice_id = models.CharField(max_length=255, blank=True, null=True)
  box_color = models.CharField(max_length=7, default='#485AFF')
  font_color = models.CharField(max_length=7, default='#FFFFFF')
  task_id = models.CharField(max_length=1000, unique=True)
  parallel_processing = models.BooleanField(default=False)
  created_at = models.DateTimeField(auto_now_add=True)

  STATUS_CHOICES = [
    ('option1', 'option1'), ('option2', 'option2'), ('option3', 'option3'),
    ('option4', 'option4')
  ]
  dimension = models.CharField(
    max_length=30, choices=STATUS_CHOICES, default='option1'
  )

  def __str__(self):
    return str(self.id)

class Task(models.Model):
  task_id = models.CharField(max_length=255)
  status = models.CharField(max_length=20, default='processing')
  aspect_ratio = models.CharField(max_length=255, default='option1')
  video_links = models.JSONField(null=True, blank=True)

  def __str__(self) -> str:
    return self.status

class Package(models.Model):
  name = models.CharField(max_length=100)
  price = models.PositiveIntegerField()
  stripe_id = models.CharField(max_length=200)
  video_limit = models.PositiveIntegerField()
  price_per_video = models.FloatField(null=True, blank=True)

  def __str__(self) -> str:
    return self.name

--- ./hooks/tests.py ---

from django.test import TestCase

# Create your tests here.

--- ./hooks/forms.py ---

from django import forms
from .models import Hook

class HookForm(forms.ModelForm):
  class Meta:
    model = Hook
    fields = [
      'hooks_content', 'google_sheets_link', 'eleven_labs_api_key', 'voice_id',
      'box_color', 'font_color'
    ]

    widgets = {
      'hooks_content':
        forms.ClearableFileInput(
          attrs={
            'id': 'hooks',
            'accept': 'video/mp4,video/x-m4v,video/*',
          }
        ),
      'google_sheets_link':
        forms.URLInput(
          attrs={
            'id': 'google_link',
            'placeholder': 'Paste URL Link',
          }
        ),
      'eleven_labs_api_key':
        forms.TextInput(
          attrs={
            'id': 'api_key',
            'placeholder': 'Paste API Key',
          }
        ),
      'voice_id':
        forms.TextInput(
          attrs={
            'id': 'voice_id',
            'placeholder': 'Enter Voice ID',
          }
        ),
      'box_color':
        forms.TextInput(
          attrs={
            'type': 'color',
            'class': 'color-input',
            'value': '#485AFF',
            'id': 'boxcolor',
            'required': 'required',
          }
        ),
      'font_color':
        forms.TextInput(
          attrs={
            'type': 'color',
            'class': 'color-input',
            'value': '#FFFFFF',
            'id': 'fontcolor',
            'required': 'required',
          }
        ),
    }

--- ./hooks/views.py ---

import logging
import tempfile
import os

from django.shortcuts import render, redirect
from django.contrib.auth.decorators import login_required
from django.http import HttpResponse, FileResponse
from django.conf import settings

from .forms import HookForm

from .tools.utils import generate_task_id
from .tools.processor import process_files

from django.http import JsonResponse
from django.shortcuts import get_object_or_404

from .models import Task
from account.models import Plan

import threading

import zipfile
import io

import requests
from .tools.spreadsheet_extractor import fetch_google_sheet_data

logging.basicConfig(level=logging.DEBUG)

def background_processing(task_id, user_sub, aspect_ratio):

  try:
    temp_dir = tempfile.mkdtemp(prefix=f"task_{task_id}_")
    logging.info(f'temp_dir ->, {temp_dir}')

    # Process the files and get video links and credits used
    video_links, credits_used = process_files(
      temp_dir,
      task_id,
      user_sub.plan.name.lower() == 'free'
      # FIXME: and user_sub.current_period_end is None
      ,
      aspect_ratio
    )
    logging.info(f"{video_links}: Video Links")
    logging.info(f'{credits_used} Credits Used.')

    # Reduce user credits and save profile
    user_sub.hooks -= credits_used
    user_sub.save()

    # Update the task status
    task = Task.objects.get(task_id=task_id)
    task.status = 'completed'
    task.video_links = video_links
    task.aspect_ratio = aspect_ratio
    task.save()

  except Exception as e:
    logging.error(f"Error during background processing: {e}")

@login_required
def upload_hook(request):
  if not request.user.is_authenticated:
    return redirect('account:home')

  hook = None
  if request.method == 'POST':
    task_id = generate_task_id()
    logging.info(f'Task ID generated --> {task_id}')

    Task.objects.create(task_id=task_id, status='processing')
    logging.info(f'A Task object created for task id --> {task_id}')

    parallel_processing = True

    form = HookForm(request.POST, request.FILES)
    is_valid_resolution = request.POST.get('resolution') in [
      'option1', 'option2', 'option3', 'option4'
    ]
    is_valid_form = form.is_valid() and \
                    is_valid_resolution
    if is_valid_form:
      hook = form.save(commit=False)
      hook.task_id = task_id
      hook.parallel_processing = parallel_processing
      hook.dimension = request.POST.get('resolution')
      hook.save()

      return redirect(
        'hooks:processing', task_id=task_id, aspect_ratio=hook.dimension
      )
    else:
      return render(request, 'upload_hook.html', {'form': form, 'hook': hook})
  else:
    form = HookForm()

  return render(request, 'upload_hook.html', {'form': form, 'hook': hook})

@login_required
def processing(request, task_id, aspect_ratio):

  # Check if the user has enough credits
  user_sub = request.user.subscription
  if user_sub.hooks <= 0:
    # You can change the url below to the stripe URL
    # return redirect('hooks:no_credits')  # Redirect to an error page or appropriate view
    return HttpResponse(
      "You don't have enough credits, buy and try again!", status=404
    )

  thread = threading.Thread(
    target=background_processing, args=(task_id, user_sub, aspect_ratio)
  )
  thread.start()

  return render(
    request, 'processing.html', {
      'task_id': task_id,
      'aspect_ratio': aspect_ratio,
    }
  )

@login_required
def check_task_status(request, task_id):
  task = get_object_or_404(Task, task_id=task_id)

  # Return task status and video links (if processing is completed)
  return JsonResponse(
    {
      'status': task.status,
      'video_links': task.video_links if task.status == 'completed' else None
    }
  )

def processing_successful(request, task_id):
  task = get_object_or_404(Task, task_id=task_id)

  return render(
    request, 'processing_successful.html', {
      'task_id': task_id,
      'video_links': task.video_links,
      'plans': Plan.objects.all(),
    }
  )

def download_video(request, videopath):
  if not os.path.exists(videopath):
    return HttpResponse("Video not found", status=404)

  response = FileResponse(open(videopath, 'rb'), content_type='video/mp4')
  response['Content-Disposition'
           ] = f'attachment; filename="{os.path.basename(videopath)}"'

  return response

def download_zip(request, task_id):
  task = get_object_or_404(Task, task_id=task_id)
  videos = task.video_links

  zip_buffer = io.BytesIO()

  with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
    for idx, video in enumerate(videos):
      if os.path.exists(video['video_link']):
        file_name = os.path.basename(video['video_link'])

        # Add the file to the zip archive
        zip_file.write(video['video_link'], file_name)

  zip_buffer.seek(0)

  # Create a response with the zip file for downloading
  response = HttpResponse(zip_buffer, content_type='application/zip')
  response['Content-Disposition'] = f'attachment; filename="hook_videos.zip"'

  return response

@login_required
def validate_google_sheet_link(request):
  if request.method == 'POST':
    google_sheets_link = request.POST.get('google_sheets_link')

    try:
      # Attempt to fetch the Google Sheets data for validation
      fetch_google_sheet_data(google_sheets_link)
      return JsonResponse({'valid': True})
    except ValueError as ve:
      return JsonResponse({'valid': False, 'error': str(ve)})
    except Exception as e:
      return JsonResponse({'valid': False, 'error': str(e)})

  return JsonResponse({'valid': False, 'error': 'Invalid request method.'})

def validate_api_key(request):
  if request.method == 'POST':
    api_key = request.POST.get('eleven_labs_api_key', '')
    voice_id = request.POST.get(
      'voice_id'
    )  # Replace with a valid default voice ID to test the API key

    # Try making a request to Eleven Labs API to validate the key
    url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"
    headers = {"xi-api-key": api_key}
    data = {
      "text": "Test voice synthesis",  # Small test text to avoid large requests
      "model_id": "eleven_monolingual_v1",
      "voice_settings": {
        "stability": 0.5,
        "similarity_boost": 0.75
      }
    }

    try:
      response = requests.post(url, json=data, headers=headers)

      if response.status_code == 200:
        return JsonResponse({'valid': True})
      else:
        error_detail = response.json().get('detail', {})

        import json
        print(json.dumps(error_detail))

        return JsonResponse(
          {
            'valid': False,
            'error': error_detail['status'],
            'message': error_detail['message'],
          }
        )
    except requests.exceptions.RequestException as _:
      return JsonResponse(
        {
          'valid': False,
          'error': 'Error Connecting To Eleven Labs API',
          'message': 'Error Connecting To Eleven Labs API',
        }
      )

--- ./dependencies/__init__.py ---


--- ./dependencies/fonts.py ---

import os
import platform
import shutil

def install_fonts():
    # Define the fonts directory
    fonts_dir = 'dependencies/fonts'
    
    # Check if the fonts directory exists
    if not os.path.exists(fonts_dir):
        print(f"Directory {fonts_dir} does not exist.")
        return

    # Get a list of all .ttf and .otf font files in the fonts directory
    font_files = [f for f in os.listdir(fonts_dir) if f.endswith('.ttf') or f.endswith('.otf')]

    if not font_files:
        print("No .ttf or .otf font files found in the directory.")
        return


    # Detect the operating system
    system = platform.system()

    if system == 'Windows':
        # Windows font installation
        fonts_dest_dir = os.path.join(os.environ['WINDIR'], 'Fonts')
        for font in font_files:
            src_font_path = os.path.join(fonts_dir, font)
            dest_font_path = os.path.join(fonts_dest_dir, font)
            print(f"Installing {font} to {fonts_dest_dir}")
            shutil.copy(src_font_path, dest_font_path)
            # Register the font
            os.system(f'REG ADD "HKLM\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\Fonts" /v "{font}" /t REG_SZ /d "{font}" /f')
        print("Fonts installed on Windows.")

    elif system == 'Darwin':
        # macOS font installation
        fonts_dest_dir = os.path.expanduser('~/Library/Fonts')
        for font in font_files:
            src_font_path = os.path.join(fonts_dir, font)
            dest_font_path = os.path.join(fonts_dest_dir, font)
            print(f"Installing {font} to {fonts_dest_dir}")
            shutil.copy(src_font_path, dest_font_path)
        print("Fonts installed on macOS.")

    else:
        print(f"Unsupported operating system: {system}")

def font_exists(font_name):
    system = platform.system()
    print(system)
    if system == 'Windows':
        fonts_dest_dir = os.path.join(os.environ['WINDIR'], 'dependencies/fonts')
        return os.path.exists(os.path.join(fonts_dest_dir, font_name))
    elif system == 'Darwin' or system == 'Linux':
        fonts_dest_dir = os.path.join(os.getcwd(), 'dependencies/fonts')
        print(fonts_dest_dir, '---------------------------')
        return os.path.exists(os.path.join(fonts_dest_dir, font_name))
    else:
        return False

--- ./dependencies/voices.py ---

from elevenlabs import VoiceSettings

VOICE_SETTINGS = {

    "Bradley - Formal and Serious":  VoiceSettings(
            stability=1,
            similarity_boost=1,
            style=0.0,
            use_speaker_boost=True,
        ),
    "Daniel":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ),
    "Brian":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Charlie":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Drew":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "James": VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Joseph":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Micheal":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Paul":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Thomas":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Domi":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Dorothy":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Emily":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Matilda":  VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ) ,
    "Serena" :   VoiceSettings(
            stability=0.5,
            similarity_boost=0.75,
            style=0.0,
            use_speaker_boost=True,
        ),

}
--- ./dependencies/imagemagick.py ---

import subprocess
import platform

def is_imagemagick_installed():
    """Check if ImageMagick is installed."""
    command = "magick --version" if platform.system() == "Windows" else "convert --version"
    try:
        subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except subprocess.CalledProcessError:
        return False

def install_imagemagick():
    """Prompt the user to install ImageMagick."""
    print("ImageMagick is required but not found on your system.")
    if platform.system() == "Windows":
        print("Please download and install ImageMagick from: https://imagemagick.org/script/download.php")
    else:
        print("You can install ImageMagick using your package manager (e.g., 'brew install imagemagick' on macOS)")


--- ./manage.py ---

#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'hooks_app.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()

--- ./hooks_app/__init__.py ---


--- ./hooks_app/settings.py ---

import os
from pathlib import Path
from dotenv import dotenv_values
from django.contrib.messages import constants as messages

BASE_DIR = Path(__file__).resolve().parent.parent
CREDENTIALS = dotenv_values(BASE_DIR / 'hooks_app/.env')

# WARNING: keep the secret key used in production secret!
SECRET_KEY = 'django-insecure-r$rtz-t^^i#q#21049me&2^1!!n8p-(w4iwfnvdh%ygz9z6+#n'

# WARNING: don't run with debug turned on in production!
DEBUG = True

ALLOWED_HOSTS = ['*']

INSTALLED_APPS = [
  'django.contrib.admin',
  'django.contrib.auth',
  'django.contrib.contenttypes',
  'django.contrib.sessions',
  'django.contrib.messages',
  'django.contrib.staticfiles',
  'account.apps.AccountConfig',
  'hooks.apps.HooksConfig',
  'merger.apps.MergerConfig',
]

MIDDLEWARE = [
  'django.middleware.security.SecurityMiddleware',
  'django.contrib.sessions.middleware.SessionMiddleware',
  'django.middleware.common.CommonMiddleware',
  'django.middleware.csrf.CsrfViewMiddleware',
  'django.contrib.auth.middleware.AuthenticationMiddleware',
  'django.contrib.messages.middleware.MessageMiddleware',
  'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'hooks_app.urls'

TEMPLATES = [
  {
    'BACKEND': 'django.template.backends.django.DjangoTemplates',
    'DIRS': [],
    'APP_DIRS': True,
    'OPTIONS':
      {
        'context_processors':
          [
            'django.template.context_processors.debug',
            'django.template.context_processors.request',
            'django.contrib.auth.context_processors.auth',
            'django.contrib.messages.context_processors.messages',
          ],
      },
  },
]

WSGI_APPLICATION = 'hooks_app.wsgi.application'

DATABASES = {
  'default':
    {
      'ENGINE': 'django.db.backends.sqlite3',
      'NAME': BASE_DIR / 'db.sqlite3',
    }
}

AUTH_PASSWORD_VALIDATORS = [
  {
    'NAME':
      'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
  },
  {
    'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
  },
  {
    'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
  },
  {
    'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
  },
]

LANGUAGE_CODE = 'en-us'
USE_I18N = True
TIME_ZONE = 'UTC'
USE_TZ = True

STATIC_URL = 'static/'
MEDIA_URL = '/media/'
MEDIA_ROOT = os.path.join(BASE_DIR, 'media')

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

AUTH_USER_MODEL = 'account.User'

AUTHENTICATION_BACKENDS = [
  'django.contrib.auth.backends.ModelBackend',
  'account.authentication.EmailAuthBackend',
]

LOGIN_REDIRECT_URL = 'hooks:upload'
LOGIN_URL = 'account:login'
LOGOUT_URL = 'account:logout'

UPLOAD_FOLDER = os.path.join(BASE_DIR, 'media', 'uploads')
OUTPUT_FOLDER = os.path.join(BASE_DIR, 'media', 'output')
if not os.path.exists(UPLOAD_FOLDER):
  os.makedirs(UPLOAD_FOLDER)
if not os.path.exists(OUTPUT_FOLDER):
  os.makedirs(OUTPUT_FOLDER)

DATA_UPLOAD_MAX_MEMORY_SIZE = 2 * 1024 * 1024 * 1024
FILE_UPLOAD_MAX_MEMORY_SIZE = 1 * 1024 * 1024 * 1024
EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'

DOMAIN = 'http://91.108.112.100:6816'
# DOMAIN = 'http://localhost:8000'

STRIPE_REDIRECT_DOMAIN = 'http://0.0.0.0:8000'
STRIPE_PRICE_ID_PRO = CREDENTIALS['STRIPE_PRICE_ID_PRO']
STRIPE_PRICE_ID_EXCLUSIVE = CREDENTIALS['STRIPE_PRICE_ID_EXCLUSIVE']
STRIPE_SEC_KEY = CREDENTIALS['STRIPE_SEC_KEY']
STRIPE_ENDPOINT_SECRET = CREDENTIALS['STRIPE_ENDPOINT_SECRET']

MESSAGE_TAGS = {
  messages.DEBUG: 'debug',
  messages.INFO: 'info',
  messages.SUCCESS: 'success',
  messages.WARNING: 'warning',
  messages.ERROR: 'error',
}

EMAIL_HOST_USER = 'support@hooksmaster.io'
EMAIL_HOST_PASSWORD = 'ddhdnjgykygwwgqv'
EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST = 'smtp.office365.com'
EMAIL_PORT = 587
EMAIL_USE_SSL = False
EMAIL_USE_TLS = True

--- ./hooks_app/wsgi.py ---

"""
WSGI config for hooks_app project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'hooks_app.settings')

application = get_wsgi_application()

--- ./hooks_app/urls.py ---

from django.contrib import admin
from django.urls import path, include
from django.conf import settings
from django.conf.urls.static import static
from django.contrib.auth import views as auth_views

urlpatterns = [
  path("", include("account.urls", namespace="account")),
  path("admin/", admin.site.urls),
  path("hooks/", include("hooks.urls", namespace="hooks")),
  path("merge/", include("merger.urls", namespace="merger")),
  path(
    "password-reset/",
    auth_views.PasswordResetView.as_view(
      template_name="registration/reset_password.html",
      email_template_name="password_reset_email_template.html",
    ),
    name="password_reset",
  ),
  path(
    "password-reset/done/",
    auth_views.PasswordResetDoneView.as_view(
      template_name="password_reset_done.html"
    ),
    name="password_reset_done",
  ),
  path(
    "reset/<uidb64>/<token>/",
    auth_views.PasswordResetConfirmView.as_view(
      template_name="password_reset_confirm.html"
    ),
    name="password_reset_confirm",
  ),
  path(
    "reset/done/",
    auth_views.PasswordResetCompleteView.as_view(
      template_name="password_reset_complete.html"
    ),
    name="password_reset_complete",
  ),
]

if settings.DEBUG:
  urlpatterns += static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)

--- ./hooks_app/asgi.py ---

"""
ASGI config for hooks_app project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.1/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'hooks_app.settings')

application = get_asgi_application()
